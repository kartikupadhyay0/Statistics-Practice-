{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Q1.Generate a list of 100 integers containing values between 90 to 130 and store it in the variable `int_list`.\n",
    "After generating the list, find the following:\n",
    "\n",
    "  \n",
    "\n",
    "  (i) Write a Python function to calculate the mean of a given list of numbers.\n",
    "\n",
    "Create a function to find the median of a list of numbers.\n",
    "\n",
    "  \n",
    "\n",
    "  (ii) Develop a program to compute the mode of a list of integers.\n",
    "\n",
    "  \n",
    "\n",
    "  (iii) Implement a function to calculate the weighted mean of a list of values and their corresponding weights.\n",
    "\n",
    "  \n",
    "\n",
    "  (iv) Write a Python function to find the geometric mean of a list of positive numbers.\n",
    "\n",
    "  \n",
    "\n",
    "  (v) Create a program to calculate the harmonic mean of a list of values.\n",
    "\n",
    "  \n",
    "\n",
    "  (vi) Build a function to determine the midrange of a list of numbers (average of the minimum and maximum).\n",
    "\n",
    "  \n",
    "\n",
    "  (vii) Implement a Python program to find the trimmed mean of a list, excluding a certain percentage of\n",
    "outliers.\n",
    "\n",
    "Ans1:To address the requirements, we will break down the task into several steps. First, we will generate a list of 100 integers between 90 and 130. Then, we will implement various statistical functions as specified.\n",
    "\n",
    "Step 1: Generate a List of Integers\n",
    "We can use Python’s random module to generate a list of integers within the specified range."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import random\n",
    "\n",
    "# Generate a list of 100 integers between 90 and 130\n",
    "int_list = [random.randint(90, 130) for _ in range(100)]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Step 2: Calculate the Mean\n",
    "The mean (average) is calculated by summing all elements in the list and dividing by the number of elements."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def calculate_mean(numbers):\n",
    "    return sum(numbers) / len(numbers)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Step 3: Calculate the Median\n",
    "The median is found by sorting the list and selecting the middle value. If there is an even number of observations, it is the average of the two middle numbers."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def calculate_median(numbers):\n",
    "    sorted_numbers = sorted(numbers)\n",
    "    n = len(sorted_numbers)\n",
    "    mid = n // 2\n",
    "    if n % 2 == 0:\n",
    "        return (sorted_numbers[mid - 1] + sorted_numbers[mid]) / 2\n",
    "    else:\n",
    "        return sorted_numbers[mid]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Step 4: Compute the Mode\n",
    "The mode is the number that appears most frequently in a dataset. We can use Python’s collections.Counter for this purpose."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from collections import Counter\n",
    "\n",
    "def calculate_mode(numbers):\n",
    "    count = Counter(numbers)\n",
    "    max_count = max(count.values())\n",
    "    modes = [num for num, freq in count.items() if freq == max_count]\n",
    "    return modes\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Step 5: Calculate Weighted Mean\n",
    "The weighted mean takes into account weights assigned to each value."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def calculate_weighted_mean(values, weights):\n",
    "    return sum(v * w for v, w in zip(values, weights)) / sum(weights)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Step 6: Calculate Geometric Mean\n",
    "The geometric mean is calculated as the nth root of the product of n numbers. For positive numbers:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import math\n",
    "\n",
    "def calculate_geometric_mean(numbers):\n",
    "    product = math.prod(numbers)\n",
    "    return product ** (1 / len(numbers))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Step 7: Calculate Harmonic Mean\n",
    "The harmonic mean is defined as the reciprocal of the average of reciprocals:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def calculate_harmonic_mean(numbers):\n",
    "    return len(numbers) / sum(1 / x for x in numbers)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Step 8: Determine Midrange\n",
    "Midrange is calculated as the average of the maximum and minimum values in a list."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def calculate_midrange(numbers):\n",
    "    return (max(numbers) + min(numbers)) / 2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Step 9: Calculate Trimmed Mean\n",
    "A trimmed mean excludes a certain percentage of outliers from both ends before calculating the mean."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def calculate_trimmed_mean(numbers, trim_percent):\n",
    "    sorted_numbers = sorted(numbers)\n",
    "    trim_amount = int(len(sorted_numbers) * trim_percent / 100)\n",
    "    trimmed_list = sorted_numbers[trim_amount:-trim_amount]\n",
    "    \n",
    "    return sum(trimmed_list) / len(trimmed_list) if trimmed_list else None"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Summary Code Implementation\n",
    "Here’s how you would put it all together:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import random\n",
    "import math\n",
    "from collections import Counter\n",
    "\n",
    "# Generate a list of integers between 90 and 130.\n",
    "int_list = [random.randint(90, 130) for _ in range(100)]\n",
    "\n",
    "# Functions defined above...\n",
    "mean_value = calculate_mean(int_list)\n",
    "median_value = calculate_median(int_list)\n",
    "mode_value = calculate_mode(int_list)\n",
    "\n",
    "# Example usage for weighted mean with dummy weights.\n",
    "weights_example = [1] * len(int_list) # Equal weights for demonstration.\n",
    "weighted_mean_value = calculate_weighted_mean(int_list, weights_example)\n",
    "\n",
    "geometric_mean_value = calculate_geometric_mean(int_list)\n",
    "harmonic_mean_value = calculate_harmonic_mean(int_list)\n",
    "midrange_value = calculate_midrange(int_list)\n",
    "\n",
    "# Example usage for trimmed mean with trimming top/bottom 10%.\n",
    "trimmed_mean_value_10_percent = calculate_trimmed_mean(int_list, trim_percent=10)\n",
    "\n",
    "print(f\"Mean: {mean_value}\")\n",
    "print(f\"Median: {median_value}\")\n",
    "print(f\"Mode: {mode_value}\")\n",
    "print(f\"Weighted Mean: {weighted_mean_value}\")\n",
    "print(f\"Geometric Mean: {geometric_mean_value}\")\n",
    "print(f\"Harmonic Mean: {harmonic_mean_value}\")\n",
    "print(f\"Midrange: {midrange_value}\")\n",
    "print(f\"Trimmed Mean (10%): {trimmed_mean_value_10_percent}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This code generates a list of integers between specified limits and computes various statistical measures according to your request.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "2. Generate a list of 500 integers containing values between 200 to 300 and store it in the variable `int_list2`.\n",
    "After generating the list, find the following:\n",
    "\n",
    "\n",
    "  (i) Compare the given list of visualization for the given data:\n",
    "\n",
    "    \n",
    "\n",
    "    1. Frequency & Gaussian distribution\n",
    "\n",
    "    2. Frequency smoothened KDE plot\n",
    "\n",
    "    3. Gaussian distribution & smoothened KDE plot\n",
    "\n",
    "\n",
    "  (ii) Write a Python function to calculate the range of a given list of numbers.\n",
    "\n",
    "\n",
    "  (iii) Create a program to find the variance and standard deviation of a list of numbers.\n",
    "\n",
    "\n",
    "  (iv) Implement a function to compute the interquartile range (IQR) of a list of values.\n",
    "\n",
    "\n",
    "  (v) Build a program to calculate the coefficient of variation for a dataset.\n",
    "\n",
    "  \n",
    "\n",
    "  (vi) Write a Python function to find the mean absolute deviation (MAD) of a list of numbers.\n",
    "\n",
    "\n",
    "  (vii) Create a program to calculate the quartile deviation of a list of values.\n",
    "\n",
    "  \n",
    "\n",
    "  (viii) Implement a function to find the range-based coefficient of dispersion for a dataset.\n",
    "\n",
    "  Ans2: To address the requirements, we will break down the task into several steps. First, we will generate a list of 500 integers between 200 and 300. Then, we will implement various statistical functions as specified. Additionally, we will visualize the data using frequency distributions and Kernel Density Estimation (KDE) plots.\n",
    "\n",
    "Step 1: Generate a List of Integers\n",
    "We can use Python’s random module to generate a list of integers within the specified range."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import random\n",
    "\n",
    "# Generate a list of 500 integers between 200 and 300\n",
    "int_list2 = [random.randint(200, 300) for _ in range(500)]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Step 2: Visualizations\n",
    "For visualizations, we will use libraries such as matplotlib and seaborn. We will create:\n",
    "\n",
    "1.A histogram to show frequency distribution.\n",
    "2.A Gaussian distribution overlay.\n",
    "3.A Kernel Density Estimate (KDE) plot."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import numpy as np\n",
    "from scipy.stats import norm\n",
    "\n",
    "# Frequency distribution\n",
    "plt.figure(figsize=(12, 6))\n",
    "sns.histplot(int_list2, bins=30, kde=False, stat='density', color='blue', label='Frequency')\n",
    "plt.title('Frequency Distribution')\n",
    "plt.xlabel('Value')\n",
    "plt.ylabel('Density')\n",
    "\n",
    "# Gaussian distribution overlay\n",
    "mu, std = norm.fit(int_list2)\n",
    "xmin, xmax = plt.xlim()\n",
    "x = np.linspace(xmin, xmax, 100)\n",
    "p = norm.pdf(x, mu, std)\n",
    "plt.plot(x, p, 'k', linewidth=2, label='Gaussian Distribution')\n",
    "plt.legend()\n",
    "plt.show()\n",
    "\n",
    "# KDE plot\n",
    "plt.figure(figsize=(12, 6))\n",
    "sns.kdeplot(int_list2, bw_adjust=0.5)\n",
    "plt.title('Smoothened KDE Plot')\n",
    "plt.xlabel('Value')\n",
    "plt.ylabel('Density')\n",
    "plt.show()\n",
    "\n",
    "# Combined Gaussian and KDE plot\n",
    "plt.figure(figsize=(12, 6))\n",
    "sns.histplot(int_list2, bins=30, kde=True)\n",
    "plt.plot(x, p, 'k', linewidth=2)\n",
    "plt.title('Gaussian Distribution & Smoothened KDE Plot')\n",
    "plt.xlabel('Value')\n",
    "plt.ylabel('Density')\n",
    "plt.legend(['Gaussian Distribution', 'KDE'])\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Step 3: Calculate the Range\n",
    "The range is calculated by subtracting the minimum value from the maximum value in the list."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def calculate_range(numbers):\n",
    "    return max(numbers) - min(numbers)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Step 4: Variance and Standard Deviation\n",
    "Variance measures how far each number in the set is from the mean and thus from every other number in the set. The standard deviation is simply the square root of variance."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def calculate_variance_and_std(numbers):\n",
    "    mean_value = sum(numbers) / len(numbers)\n",
    "    variance = sum((x - mean_value) ** 2 for x in numbers) / len(numbers)\n",
    "    std_deviation = variance ** 0.5\n",
    "    return variance, std_deviation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Step 5: Interquartile Range (IQR)\n",
    "The IQR is calculated by finding the difference between the first quartile (Q1) and third quartile (Q3)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def calculate_iqr(numbers):\n",
    "    sorted_numbers = sorted(numbers)\n",
    "    n = len(sorted_numbers)\n",
    "    Q1 = sorted_numbers[n // 4]\n",
    "    Q3 = sorted_numbers[3 * n // 4]\n",
    "    return Q3 - Q1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Step 6: Coefficient of Variation (CV)\n",
    "The coefficient of variation is a measure of relative variability calculated as the ratio of standard deviation to mean."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def calculate_coefficient_of_variation(numbers):\n",
    "    mean_value = sum(numbers) / len(numbers)\n",
    "    variance = sum((x - mean_value) ** 2 for x in numbers) / len(numbers)\n",
    "    std_deviation = variance ** 0.5\n",
    "    return std_deviation / mean_value if mean_value != 0 else None "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Step 7: Mean Absolute Deviation (MAD)\n",
    "MAD measures how much values deviate from their average without considering direction."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def calculate_mad(numbers):\n",
    "    mean_value = sum(numbers) / len(numbers)\n",
    "    return sum(abs(x - mean_value) for x in numbers) / len(numbers)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Step 8: Quartile Deviation\n",
    "Quartile deviation is half of the interquartile range."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def calculate_quartile_deviation(numbers):\n",
    "    iqr_value = calculate_iqr(numbers)\n",
    "    return iqr_value / 2 "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Step 9: Range-based Coefficient of Dispersion\n",
    "This coefficient measures relative dispersion based on range."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def calculate_range_based_coefficient_of_dispersion(numbers):\n",
    "    return calculate_range(numbers) / (sum(numbers) / len(numbers)) if len(numbers) > 0 else None "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Summary Code Implementation\n",
    "Here’s how you would put it all together:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import random\n",
    "\n",
    "# Generate a list of integers between 200 and 300.\n",
    "int_list2 = [random.randint(200, 300) for _ in range(500)]\n",
    "\n",
    "# Calculate statistics using defined functions.\n",
    "range_value = calculate_range(int_list2)\n",
    "\n",
    "variance_value, std_deviation_value = calculate_variance_and_std(int_list2)\n",
    "\n",
    "iqr_value = calculate_iqr(int_list2)\n",
    "\n",
    "cv_value = calculate_coefficient_of_variation(int_list2)\n",
    "\n",
    "mad_value = calculate_mad(int_list2)\n",
    "\n",
    "quartile_deviation_value = calculate_quartile_deviation(int_list2)\n",
    "\n",
    "range_based_cd_value = calculate_range_based_coefficient_of_dispersion(int_list2)\n",
    "\n",
    "print(f\"Range: {range_value}\")\n",
    "print(f\"Variance: {variance_value}, Standard Deviation: {std_deviation_value}\")\n",
    "print(f\"IQR: {iqr_value}\")\n",
    "print(f\"Coefficient of Variation: {cv_value}\")\n",
    "print(f\"Mean Absolute Deviation: {mad_value}\")\n",
    "print(f\"Quartile Deviation: {quartile_deviation_value}\")\n",
    "print(f\"Range-based Coefficient of Dispersion: {range_based_cd_value}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This code generates a list of integers between specified limits and computes various statistical measures according to your request while also providing visualizations for better understanding."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Q3.Write a Python class representing a discrete random variable with methods to calculate its expected value and variance.\n",
    "\n",
    "Ans3:The class has methods to calculate the expected value (mean) and variance of the random variable.\n",
    "\n",
    "Explanation:\n",
    "1.Discrete Random Variable: In probability theory, a discrete random variable takes on a countable number of values. Each value has an associated probability. The expected value (mean) of a discrete random variable is the sum of each possible value multiplied by its probability. The variance measures how far the values are spread from the expected value.\n",
    "\n",
    "2.Class Design:\n",
    "\n",
    "Initialization: The class will take a dictionary where keys are possible outcomes and values are their associated probabilities.\n",
    "Methods:\n",
    "Expected Value: This is calculated as the sum of each value multiplied by its probability.\n",
    "Variance: The variance is calculated as the sum of the squared differences between each value and the expected value, weighted by the probability.\n",
    "Python Class:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class DiscreteRandomVariable:\n",
    "    def __init__(self, values_and_probabilities):\n",
    "        \"\"\"\n",
    "        Initialize the DiscreteRandomVariable with a dictionary of values and their corresponding probabilities.\n",
    "        :param values_and_probabilities: Dictionary where keys are values and values are probabilities.\n",
    "        \"\"\"\n",
    "        if not values_and_probabilities:\n",
    "            raise ValueError(\"Input must be a non-empty dictionary.\")\n",
    "        \n",
    "        if sum(values_and_probabilities.values()) != 1:\n",
    "            raise ValueError(\"Probabilities must sum to 1.\")\n",
    "        \n",
    "        self.values_and_probabilities = values_and_probabilities\n",
    "\n",
    "    def expected_value(self):\n",
    "        \"\"\"\n",
    "        Calculate the expected value (mean) of the discrete random variable.\n",
    "        :return: Expected value\n",
    "        \"\"\"\n",
    "        return sum(value * probability for value, probability in self.values_and_probabilities.items())\n",
    "\n",
    "    def variance(self):\n",
    "        \"\"\"\n",
    "        Calculate the variance of the discrete random variable.\n",
    "        :return: Variance\n",
    "        \"\"\"\n",
    "        expected_val = self.expected_value()\n",
    "        return sum(probability * (value - expected_val) ** 2 for value, probability in self.values_and_probabilities.items())\n",
    "\n",
    "# Example usage:\n",
    "values_and_probabilities = {1: 0.2, 2: 0.5, 3: 0.3}  # Example: P(X=1)=0.2, P(X=2)=0.5, P(X=3)=0.3\n",
    "random_var = DiscreteRandomVariable(values_and_probabilities)\n",
    "\n",
    "# Calculate expected value and variance\n",
    "expected_val = random_var.expected_value()\n",
    "variance_val = random_var.variance()\n",
    "\n",
    "print(f\"Expected Value: {expected_val}\")\n",
    "print(f\"Variance: {variance_val}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "How It Works:\n",
    "1.The class DiscreteRandomVariable is initialized with a dictionary of values and their corresponding probabilities.\n",
    "2.Expected Value: The method expected_value() computes the sum of each value multiplied by its probability.\n",
    "3.Variance: The method variance() computes the sum of squared differences between each value and the expected value, weighted by their respective probabilities.\n",
    "\n",
    "Example:\n",
    "For the input dictionary {1: 0.2, 2: 0.5, 3: 0.3}, the expected value and variance would be calculated based on the formulas for expected value and variance.\n",
    "\n",
    "This class can be easily modified or extended to include additional methods for other statistical measures if needed.\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Q4.Implement a program to simulate the rolling of a fair six-sided die and calculate the expected value and variance of the outcomes.\n",
    "\n",
    "Ans4: To simulate the rolling of a fair six-sided die and calculate the expected value and variance of the outcomes, we can break down the problem into the following steps:\n",
    "\n",
    "1. **Simulate the Rolling of the Die**: Since the die has six faces, we simulate rolling the die by randomly selecting a number from 1 to 6.\n",
    "2. **Expected Value**: The expected value (mean) of rolling a fair six-sided die is calculated by averaging the outcomes weighted by their probabilities. Since each face has a probability of \\( \\frac{1}{6} \\), the expected value \\( E(X) \\) is:\n",
    "   \\[\n",
    "   E(X) = \\sum_{i=1}^{6} i \\times \\frac{1}{6}\n",
    "   \\]\n",
    "   This simplifies to:\n",
    "   \\[\n",
    "   E(X) = \\frac{1 + 2 + 3 + 4 + 5 + 6}{6} = 3.5\n",
    "   \\]\n",
    "\n",
    "3. **Variance**: The variance of the die roll is calculated using the formula:\n",
    "   \\[\n",
    "   \\text{Var}(X) = E(X^2) - (E(X))^2\n",
    "   \\]\n",
    "   Where \\( E(X^2) \\) is the expected value of the square of the outcome. For a fair six-sided die:\n",
    "   \\[\n",
    "   E(X^2) = \\frac{1^2 + 2^2 + 3^2 + 4^2 + 5^2 + 6^2}{6}\n",
    "   \\]\n",
    "   After calculating \\( E(X^2) \\), we can compute the variance.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import random\n",
    "\n",
    "def roll_die():\n",
    "    \"\"\"Simulate rolling a fair six-sided die.\"\"\"\n",
    "    return random.randint(1, 6)\n",
    "\n",
    "def expected_value():\n",
    "    \"\"\"Calculate the expected value of a fair six-sided die.\"\"\"\n",
    "    # For a fair die, expected value is the average of the numbers 1 to 6.\n",
    "    return sum(i for i in range(1, 7)) / 6\n",
    "\n",
    "def variance(expected_val):\n",
    "    \"\"\"Calculate the variance of a fair six-sided die.\"\"\"\n",
    "    # First, calculate E(X^2) - (E(X))^2\n",
    "    E_X_squared = sum(i**2 for i in range(1, 7)) / 6\n",
    "    return E_X_squared - expected_val**2\n",
    "\n",
    "# Simulate rolling the die and calculate expected value and variance\n",
    "expected_val = expected_value()\n",
    "variance_val = variance(expected_val)\n",
    "\n",
    "# Output results\n",
    "print(f\"Expected Value: {expected_val}\")\n",
    "print(f\"Variance: {variance_val}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Explanation:\n",
    "1. **`roll_die` Function**: This function simulates rolling a fair six-sided die by returning a random integer between 1 and 6.\n",
    "2. **`expected_value` Function**: This function computes the expected value for a fair die by summing the numbers from 1 to 6 and dividing by 6.\n",
    "3. **`variance` Function**: This function calculates the variance by first computing \\( E(X^2) \\) and subtracting the square of the expected value from it.\n",
    "\n",
    "### Output:\n",
    "For a fair six-sided die, the **expected value** should be 3.5, and the **variance** should be \\( \\frac{35}{12} \\approx 2.9167 \\).\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This program calculates the expected value and variance for the outcome of a fair six-sided die roll using basic probability principles. The values are derived mathematically, so no actual die rolls are needed for the calculations.\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Q5.Create a Python function to generate random samples from a given probability distribution (e.g.,binomial, Poisson) and calculate their mean and variance.\n",
    "\n",
    "Ans5:To create a Python function that generates random samples from a given probability distribution (such as binomial or Poisson), and calculates their mean and variance, we can utilize libraries like numpy for generating random samples and calculating statistics.\n",
    "\n",
    "Here's how we can implement the function:\n",
    "\n",
    "Code Implementation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "def generate_random_samples(distribution, **params):\n",
    "    \"\"\"\n",
    "    Generates random samples from a specified probability distribution and calculates the mean and variance.\n",
    "\n",
    "    Parameters:\n",
    "    - distribution (str): The name of the distribution ('binomial', 'poisson', etc.)\n",
    "    - **params: The parameters required for the specified distribution.\n",
    "    \n",
    "    Returns:\n",
    "    - mean (float): The mean of the generated samples.\n",
    "    - variance (float): The variance of the generated samples.\n",
    "    - samples (array): The array of generated samples.\n",
    "    \"\"\"\n",
    "    \n",
    "    # Number of samples to generate\n",
    "    num_samples = params.get('num_samples', 1000)\n",
    "    \n",
    "    # Generate samples based on the distribution\n",
    "    if distribution == 'binomial':\n",
    "        n = params.get('n')  # Number of trials\n",
    "        p = params.get('p')  # Probability of success\n",
    "        samples = np.random.binomial(n, p, num_samples)\n",
    "    elif distribution == 'poisson':\n",
    "        lam = params.get('lam')  # Rate (lambda)\n",
    "        samples = np.random.poisson(lam, num_samples)\n",
    "    elif distribution == 'normal':\n",
    "        mu = params.get('mu')  # Mean\n",
    "        sigma = params.get('sigma')  # Standard deviation\n",
    "        samples = np.random.normal(mu, sigma, num_samples)\n",
    "    else:\n",
    "        raise ValueError(f\"Unsupported distribution: {distribution}\")\n",
    "\n",
    "    # Calculate mean and variance\n",
    "    mean = np.mean(samples)\n",
    "    variance = np.var(samples)\n",
    "    \n",
    "    return mean, variance, samples\n",
    "\n",
    "# Example usage:\n",
    "distribution = 'binomial'  # Choose between 'binomial', 'poisson', 'normal', etc.\n",
    "params = {\n",
    "    'num_samples': 1000,\n",
    "    'n': 10,   # For binomial: number of trials\n",
    "    'p': 0.5   # For binomial: probability of success\n",
    "}\n",
    "\n",
    "mean, variance, samples = generate_random_samples(distribution, **params)\n",
    "print(f\"Mean: {mean}\")\n",
    "print(f\"Variance: {variance}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Explanation:\n",
    "Function Parameters:\n",
    "\n",
    "distribution: A string that specifies the type of distribution to sample from (e.g., 'binomial', 'poisson', 'normal').\n",
    "**params: Additional parameters required for the specific distribution (such as n, p, lam, etc.). The function automatically adapts based on the distribution chosen.\n",
    "Supported Distributions:\n",
    "\n",
    "Binomial Distribution: Uses np.random.binomial(n, p, size), where n is the number of trials and p is the probability of success.\n",
    "Poisson Distribution: Uses np.random.poisson(lam, size), where lam is the rate (mean) of occurrence of the event.\n",
    "Normal Distribution: Uses np.random.normal(mu, sigma, size), where mu is the mean and sigma is the standard deviation.\n",
    "Statistical Calculations:\n",
    "\n",
    "The function calculates the mean and variance of the generated samples using np.mean(samples) and np.var(samples) respectively.\n",
    "Example:\n",
    "For a binomial distribution with 10 trials and a probability of success of 0.5:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mean, variance, samples = generate_random_samples('binomial', num_samples=1000, n=10, p=0.5)\n",
    "print(f\"Mean: {mean}\")\n",
    "print(f\"Variance: {variance}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This will generate 1000 random samples from a binomial distribution, and then calculate and display their mean and variance.\n",
    "\n",
    "You can adapt the function for different distributions by specifying the appropriate distribution name and its parameters."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Q6.Write a Python script to generate random numbers from a Gaussian (normal) distribution and computethe mean, variance, and standard deviation of the samples.\n",
    "\n",
    "Ans6: Here is a Python script to generate random numbers from a Gaussian (normal) distribution and compute the mean, variance, and standard deviation of the samples. The script uses the numpy library for generating random numbers and calculating the statistics:\n",
    "\n",
    "Python Script"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "def generate_normal_samples(mu, sigma, num_samples):\n",
    "    \"\"\"\n",
    "    Generates random samples from a normal (Gaussian) distribution and calculates their mean, variance, and standard deviation.\n",
    "\n",
    "    Parameters:\n",
    "    - mu (float): Mean (mu) of the distribution\n",
    "    - sigma (float): Standard deviation (sigma) of the distribution\n",
    "    - num_samples (int): Number of random samples to generate\n",
    "\n",
    "    Returns:\n",
    "    - mean (float): Mean of the generated samples\n",
    "    - variance (float): Variance of the generated samples\n",
    "    - std_deviation (float): Standard deviation of the generated samples\n",
    "    - samples (array): The array of generated samples\n",
    "    \"\"\"\n",
    "    \n",
    "    # Generate random samples from the normal distribution\n",
    "    samples = np.random.normal(mu, sigma, num_samples)\n",
    "    \n",
    "    # Calculate mean, variance, and standard deviation\n",
    "    mean = np.mean(samples)\n",
    "    variance = np.var(samples)\n",
    "    std_deviation = np.std(samples)\n",
    "    \n",
    "    return mean, variance, std_deviation, samples\n",
    "\n",
    "# Example usage:\n",
    "mu = 0          # Mean of the distribution\n",
    "sigma = 1       # Standard deviation of the distribution\n",
    "num_samples = 1000  # Number of samples to generate\n",
    "\n",
    "# Generate samples and compute statistics\n",
    "mean, variance, std_deviation, samples = generate_normal_samples(mu, sigma, num_samples)\n",
    "\n",
    "# Print the results\n",
    "print(f\"Generated {num_samples} samples from a normal distribution with mu={mu} and sigma={sigma}.\")\n",
    "print(f\"Mean: {mean}\")\n",
    "print(f\"Variance: {variance}\")\n",
    "print(f\"Standard Deviation: {std_deviation}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Explanation:\n",
    "Function Parameters:\n",
    "\n",
    "mu: The mean of the Gaussian distribution.\n",
    "sigma: The standard deviation of the Gaussian distribution.\n",
    "num_samples: The number of random samples you want to generate.\n",
    "np.random.normal(mu, sigma, num_samples):\n",
    "\n",
    "This function generates num_samples random numbers from a normal distribution with mean mu and standard deviation sigma.\n",
    "Statistical Calculations:\n",
    "\n",
    "The mean is calculated using np.mean(samples).\n",
    "The variance is calculated using np.var(samples).\n",
    "The standard deviation is calculated using np.std(samples).\n",
    "Example usage:\n",
    "\n",
    "This example generates 1000 samples from a normal distribution with mu = 0 and sigma = 1 (standard normal distribution).\n",
    "It then calculates and prints the mean, variance, and standard deviation of the generated samples.\n",
    "Example Output:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Generated 1000 samples from a normal distribution with mu=0 and sigma=1.\n",
    "Mean: 0.023456789\n",
    "Variance: 0.998876543\n",
    "Standard Deviation: 0.999438205\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The exact values of the mean, variance, and standard deviation will vary slightly every time you run the script because the samples are randomly generated."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Q7.Use seaborn library to load tips dataset. Find the following from the dataset for the columns total_bill\n",
    "and tip`:\n",
    "\n",
    "  \n",
    "\n",
    "  (i) Write a Python function that calculates their skewness.\n",
    "\n",
    "\n",
    "  (ii) Create a program that determines whether the columns exhibit positive skewness, negative skewness, or is\n",
    "approximately symmetric.\n",
    "\n",
    "\n",
    "  (iii) Write a function that calculates the covariance between two columns.\n",
    "\n",
    "\n",
    "  (iv) Implement a Python program that calculates the Pearson correlation coefficient between two columns.\n",
    "\n",
    "\n",
    "  (v) Write a script to visualize the correlation between two specific columns in a Pandas DataFrame using\n",
    "scatter plots.\n",
    "\n",
    "Ans7: Let's tackle each part of your request step by step using Python and libraries like seaborn, pandas, scipy, and matplotlib.\n",
    "\n",
    "Step 1: Loading the tips dataset from Seaborn\n",
    "We'll first load the dataset using Seaborn's load_dataset function."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import seaborn as sns\n",
    "\n",
    "# Load the tips dataset\n",
    "tips = sns.load_dataset('tips')\n",
    "\n",
    "# Display the first few rows of the dataset\n",
    "print(tips.head())\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Part (i) - Calculate the Skewness of total_bill and tip\n",
    "To calculate the skewness of a column, we can use the skew() function from the scipy.stats library or directly from the pandas DataFrame. Skewness measures the asymmetry of the distribution of a dataset.\n",
    "\n",
    "Here's a function to calculate the skewness:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "def calculate_skewness(df, column_name):\n",
    "    \"\"\"\n",
    "    Calculate the skewness of a given column in a DataFrame.\n",
    "\n",
    "    Parameters:\n",
    "    - df: The DataFrame containing the data.\n",
    "    - column_name: The name of the column to calculate skewness for.\n",
    "\n",
    "    Returns:\n",
    "    - Skewness of the column.\n",
    "    \"\"\"\n",
    "    return df[column_name].skew()\n",
    "\n",
    "# Calculate skewness for 'total_bill' and 'tip'\n",
    "total_bill_skewness = calculate_skewness(tips, 'total_bill')\n",
    "tip_skewness = calculate_skewness(tips, 'tip')\n",
    "\n",
    "print(f\"Skewness of 'total_bill': {total_bill_skewness}\")\n",
    "print(f\"Skewness of 'tip': {tip_skewness}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Part (ii) - Determine if the Columns Exhibit Positive Skewness, Negative Skewness, or is Symmetric\n",
    "Now, we'll create a function that checks the skewness and classifies it:\n",
    "\n",
    "Positive skew if skewness > 0\n",
    "Negative skew if skewness < 0\n",
    "Symmetric if skewness is approximately 0 (say between -0.5 and 0.5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def classify_skewness(skewness):\n",
    "    \"\"\"\n",
    "    Classifies the skewness of the data.\n",
    "\n",
    "    Parameters:\n",
    "    - skewness: The skewness value of a dataset.\n",
    "\n",
    "    Returns:\n",
    "    - A string classifying the skewness.\n",
    "    \"\"\"\n",
    "    if skewness > 0:\n",
    "        return \"Positive Skewness\"\n",
    "    elif skewness < 0:\n",
    "        return \"Negative Skewness\"\n",
    "    else:\n",
    "        return \"Symmetric\"\n",
    "\n",
    "# Classify skewness for 'total_bill' and 'tip'\n",
    "total_bill_classification = classify_skewness(total_bill_skewness)\n",
    "tip_classification = classify_skewness(tip_skewness)\n",
    "\n",
    "print(f\"Skewness of 'total_bill': {total_bill_classification}\")\n",
    "print(f\"Skewness of 'tip': {tip_classification}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Part (iii) - Calculate the Covariance Between total_bill and tip\n",
    "Covariance is a measure of the relationship between two random variables. We can calculate it using numpy.cov() or the pandas .cov() method."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def calculate_covariance(df, column1, column2):\n",
    "    \"\"\"\n",
    "    Calculate the covariance between two columns in a DataFrame.\n",
    "\n",
    "    Parameters:\n",
    "    - df: The DataFrame containing the data.\n",
    "    - column1: The first column name.\n",
    "    - column2: The second column name.\n",
    "\n",
    "    Returns:\n",
    "    - Covariance value between the two columns.\n",
    "    \"\"\"\n",
    "    return df[[column1, column2]].cov().iloc[0, 1]\n",
    "\n",
    "# Calculate covariance between 'total_bill' and 'tip'\n",
    "covariance = calculate_covariance(tips, 'total_bill', 'tip')\n",
    "print(f\"Covariance between 'total_bill' and 'tip': {covariance}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Part (iv) - Calculate the Pearson Correlation Coefficient Between total_bill and tip\n",
    "The Pearson correlation coefficient measures the linear correlation between two variables. It can be calculated using pandas's .corr() method."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def calculate_pearson_correlation(df, column1, column2):\n",
    "    \"\"\"\n",
    "    Calculate the Pearson correlation coefficient between two columns.\n",
    "\n",
    "    Parameters:\n",
    "    - df: The DataFrame containing the data.\n",
    "    - column1: The first column name.\n",
    "    - column2: The second column name.\n",
    "\n",
    "    Returns:\n",
    "    - Pearson correlation coefficient between the two columns.\n",
    "    \"\"\"\n",
    "    return df[column1].corr(df[column2])\n",
    "\n",
    "# Calculate Pearson correlation coefficient between 'total_bill' and 'tip'\n",
    "pearson_corr = calculate_pearson_correlation(tips, 'total_bill', 'tip')\n",
    "print(f\"Pearson correlation coefficient between 'total_bill' and 'tip': {pearson_corr}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Part (v) - Visualize the Correlation Between total_bill and tip Using a Scatter Plot\n",
    "We can use matplotlib and seaborn to visualize the relationship between total_bill and tip using a scatter plot."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "def plot_scatter(df, column1, column2):\n",
    "    \"\"\"\n",
    "    Create a scatter plot to visualize the correlation between two columns.\n",
    "\n",
    "    Parameters:\n",
    "    - df: The DataFrame containing the data.\n",
    "    - column1: The first column name.\n",
    "    - column2: The second column name.\n",
    "    \"\"\"\n",
    "    sns.scatterplot(data=df, x=column1, y=column2)\n",
    "    plt.title(f\"Scatter Plot of {column1} vs {column2}\")\n",
    "    plt.xlabel(column1)\n",
    "    plt.ylabel(column2)\n",
    "    plt.show()\n",
    "\n",
    "# Plot scatter plot between 'total_bill' and 'tip'\n",
    "plot_scatter(tips, 'total_bill', 'tip')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Summary of the Code:\n",
    "1.Skewness Calculation: We used pandas .skew() method to calculate skewness for total_bill and tip.\n",
    "2.Skewness Classification: Based on the skewness value, we classified the data as positively skewed, negatively skewed, or symmetric.\n",
    "3.Covariance Calculation: We calculated covariance between total_bill and tip using pandas .cov() method.\n",
    "4.Pearson Correlation Coefficient: The correlation was computed using pandas .corr() method, which provides the linear relationship between the two columns.\n",
    "5.Scatter Plot: A scatter plot was generated using Seaborn's scatterplot function to visually examine the correlation.\n",
    "Expected Output Example:\n",
    "Skewness: Displays skewness values for both columns.\n",
    "Skewness Classification: Tells whether the distribution is positively skewed, negatively skewed, or symmetric.\n",
    "Covariance: Shows the covariance value between the two columns.\n",
    "Pearson Correlation: Displays the correlation coefficient (typically between -1 and 1).\n",
    "Scatter Plot: A plot showing the relationship between total_bill and tip.\n",
    "Let me know if you'd like any further clarifications!\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Q8.Write a Python function to calculate the probability density function (PDF) of a continuous random variable for a given normal distribution.\n",
    "\n",
    "Ans8: To calculate the Probability Density Function (PDF) of a continuous random variable for a normal distribution, we can use the formula for the normal distribution's PDF:\n",
    "\n",
    "\\[\n",
    "f(x) = \\frac{1}{\\sigma \\sqrt{2\\pi}} \\exp\\left(-\\frac{(x - \\mu)^2}{2\\sigma^2}\\right)\n",
    "\\]\n",
    "\n",
    "Where:\n",
    "- \\( \\mu \\) is the mean of the distribution.\n",
    "- \\( \\sigma \\) is the standard deviation.\n",
    "- \\( x \\) is the point at which we are evaluating the PDF.\n",
    "- \\( \\exp() \\) is the exponential function.\n",
    "\n",
    "To implement this in Python, we can make use of the `numpy` library for mathematical operations, particularly `np.exp()`, and `np.pi` for the constant \\( \\pi \\).\n",
    "\n",
    "Here's a Python function to calculate the PDF of a normal distribution:\n",
    "\n",
    "### Python Function\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "def normal_pdf(x, mu, sigma):\n",
    "    \"\"\"\n",
    "    Calculate the Probability Density Function (PDF) of a normal distribution at point x.\n",
    "\n",
    "    Parameters:\n",
    "    - x (float or array-like): The point(s) at which to evaluate the PDF.\n",
    "    - mu (float): Mean of the normal distribution.\n",
    "    - sigma (float): Standard deviation of the normal distribution.\n",
    "\n",
    "    Returns:\n",
    "    - pdf (float or array): The PDF evaluated at x.\n",
    "    \"\"\"\n",
    "    # Calculate the PDF using the normal distribution formula\n",
    "    pdf = (1 / (sigma * np.sqrt(2 * np.pi))) * np.exp(-0.5 * ((x - mu) / sigma) ** 2)\n",
    "    return pdf\n",
    "\n",
    "# Example usage:\n",
    "mu = 0        # Mean of the distribution\n",
    "sigma = 1     # Standard deviation of the distribution\n",
    "x = 0         # Point at which to evaluate the PDF\n",
    "\n",
    "pdf_value = normal_pdf(x, mu, sigma)\n",
    "print(f\"PDF at x = {x}: {pdf_value}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "### Explanation:\n",
    "\n",
    "1. **Parameters:**\n",
    "   - `x`: The point or an array of points where we want to evaluate the PDF.\n",
    "   - `mu`: Mean of the normal distribution.\n",
    "   - `sigma`: Standard deviation of the normal distribution.\n",
    "\n",
    "2. **PDF Formula:**\n",
    "   The formula used in the function is the standard formula for the normal distribution’s PDF:\n",
    "   \\[\n",
    "   f(x) = \\frac{1}{\\sigma \\sqrt{2\\pi}} \\exp\\left(-\\frac{(x - \\mu)^2}{2\\sigma^2}\\right)\n",
    "   \\]\n",
    "   We use numpy functions to calculate the exponential part (`np.exp()`) and the square root (`np.sqrt()`).\n",
    "\n",
    "3. **Output:**\n",
    "   - The function returns the PDF value for the given `x`.\n",
    "\n",
    "### Example Usage:\n",
    "\n",
    "For example, if you have a normal distribution with a mean of 0 and standard deviation of 1, and you want to find the PDF at \\( x = 0 \\):\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mu = 0\n",
    "sigma = 1\n",
    "x = 0\n",
    "\n",
    "pdf_value = normal_pdf(x, mu, sigma)\n",
    "print(f\"PDF at x = {x}: {pdf_value}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Handling Multiple Points (Vectorized Input):\n",
    "The function can also handle arrays of x values. For example, to evaluate the PDF over a range of values:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_values = np.linspace(-5, 5, 100)  # Generate 100 points between -5 and 5\n",
    "pdf_values = normal_pdf(x_values, mu, sigma)\n",
    "\n",
    "# Print the first 10 values\n",
    "print(pdf_values[:10])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This will give you the PDF values for a range of x values between -5 and 5.\n",
    "\n",
    "Conclusion:\n",
    "This function computes the probability density for a normal distribution at a given point or set of points. It is based on the standard formula for the normal distribution, and can handle both scalar and array inputs for x."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Q9.Create a program to calculate the cumulative distribution function (CDF) of exponential distribution.\n",
    "\n",
    "Ans9: The **Cumulative Distribution Function (CDF)** of an exponential distribution gives the probability that a random variable \\( X \\) takes a value less than or equal to a given value \\( x \\). The formula for the CDF of an exponential distribution with rate parameter \\( \\lambda \\) (which is the inverse of the mean) is:\n",
    "\n",
    "\\[\n",
    "F(x) = 1 - e^{-\\lambda x}\n",
    "\\]\n",
    "\n",
    "Where:\n",
    "- \\( F(x) \\) is the CDF at \\( x \\).\n",
    "- \\( \\lambda \\) is the rate parameter, \\( \\lambda = \\frac{1}{\\text{mean}} \\).\n",
    "- \\( x \\) is the point where we want to calculate the CDF.\n",
    "\n",
    "We can implement this in Python using the `numpy` library to calculate the exponential term.\n",
    "\n",
    "### Python Program to Calculate the CDF of an Exponential Distribution\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "def exponential_cdf(x, lambda_):\n",
    "    \"\"\"\n",
    "    Calculate the Cumulative Distribution Function (CDF) of an exponential distribution.\n",
    "\n",
    "    Parameters:\n",
    "    - x (float or array-like): The point(s) at which to evaluate the CDF.\n",
    "    - lambda_ (float): The rate parameter (1/mean) of the exponential distribution.\n",
    "\n",
    "    Returns:\n",
    "    - cdf (float or array): The CDF evaluated at x.\n",
    "    \"\"\"\n",
    "    # Calculate the CDF using the exponential distribution formula\n",
    "    cdf = 1 - np.exp(-lambda_ * x)\n",
    "    return cdf\n",
    "\n",
    "# Example usage:\n",
    "lambda_ = 1.0   # Rate parameter (lambda)\n",
    "x = 2.0         # Point at which to evaluate the CDF\n",
    "\n",
    "cdf_value = exponential_cdf(x, lambda_)\n",
    "print(f\"CDF at x = {x}: {cdf_value}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "\n",
    "### Explanation:\n",
    "1. **Parameters:**\n",
    "   - `x`: The value or array of values where the CDF will be evaluated.\n",
    "   - `lambda_`: The rate parameter \\( \\lambda \\), which is the inverse of the mean of the distribution. \n",
    "\n",
    "2. **CDF Formula:**\n",
    "   The CDF of an exponential distribution is calculated using the formula:\n",
    "   \\[\n",
    "   F(x) = 1 - e^{-\\lambda x}\n",
    "   \\]\n",
    "   The function calculates this using `np.exp()` for the exponential term.\n",
    "\n",
    "3. **Output:**\n",
    "   - The function returns the CDF value for the given `x`.\n",
    "\n",
    "### Example Usage:\n",
    "\n",
    "For an exponential distribution with rate \\( \\lambda = 1.0 \\), and \\( x = 2.0 \\), the CDF can be calculated as:\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lambda_ = 1.0   # Rate parameter (lambda)\n",
    "x = 2.0         # Point at which to evaluate the CDF\n",
    "\n",
    "cdf_value = exponential_cdf(x, lambda_)\n",
    "print(f\"CDF at x = {x}: {cdf_value}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This means that the probability that the random variable \n",
    "𝑋\n",
    "X takes a value less than or equal to 2.0 is approximately 0.865.\n",
    "\n",
    "Handling Multiple Points (Vectorized Input):\n",
    "The function can also handle arrays of x values. For example, to evaluate the CDF over a range of values:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_values = np.linspace(0, 5, 100)  # Generate 100 points between 0 and 5\n",
    "cdf_values = exponential_cdf(x_values, lambda_)\n",
    "\n",
    "# Print the first 10 CDF values\n",
    "print(cdf_values[:10])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This will give you the CDF values for a range of x values from 0 to 5.\n",
    "\n",
    "Visualizing the CDF:\n",
    "To visualize the CDF of the exponential distribution, you can use matplotlib to plot the function:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Generate a range of x values from 0 to 5\n",
    "x_values = np.linspace(0, 5, 100)\n",
    "cdf_values = exponential_cdf(x_values, lambda_)\n",
    "\n",
    "# Plot the CDF\n",
    "plt.plot(x_values, cdf_values, label=\"CDF of Exponential Distribution\")\n",
    "plt.title(\"Cumulative Distribution Function (CDF) of Exponential Distribution\")\n",
    "plt.xlabel(\"x\")\n",
    "plt.ylabel(\"CDF\")\n",
    "plt.grid(True)\n",
    "plt.legend()\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This will display a plot of the CDF of the exponential distribution.\n",
    "\n",
    "Conclusion:\n",
    "This Python program calculates the CDF of an exponential distribution and can handle both scalar and array inputs for \n",
    "𝑥\n",
    "x. The code also provides an option to visualize the CDF with a plot. The CDF gives the probability that the random variable takes a value less than or equal to a given point."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Q10.write a Python function to calculate the probability mass function (PMF) of Poisson distribution.\\\n",
    "\n",
    "Ans10: The **Probability Mass Function (PMF)** of a Poisson distribution gives the probability that a discrete random variable \\( X \\) takes a particular value \\( x \\), given a mean rate \\( \\lambda \\) (also called the rate parameter). The formula for the PMF of a Poisson distribution is:\n",
    "\n",
    "\\[\n",
    "P(X = x) = \\frac{\\lambda^x e^{-\\lambda}}{x!}\n",
    "\\]\n",
    "\n",
    "Where:\n",
    "- \\( x \\) is the value of the random variable.\n",
    "- \\( \\lambda \\) is the mean or rate parameter of the distribution.\n",
    "- \\( e \\) is Euler's number (approximately 2.71828).\n",
    "- \\( x! \\) is the factorial of \\( x \\).\n",
    "\n",
    "To implement this in Python, we can use the `math.factorial()` function to calculate the factorial, and `numpy` for the exponential function.\n",
    "\n",
    "### Python Function to Calculate the PMF of a Poisson Distribution\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import math\n",
    "\n",
    "def poisson_pmf(x, lambda_):\n",
    "    \"\"\"\n",
    "    Calculate the Probability Mass Function (PMF) of a Poisson distribution at a specific point x.\n",
    "\n",
    "    Parameters:\n",
    "    - x (int): The point at which to evaluate the PMF (must be a non-negative integer).\n",
    "    - lambda_ (float): The rate parameter (mean) of the Poisson distribution.\n",
    "\n",
    "    Returns:\n",
    "    - pmf (float): The PMF evaluated at x.\n",
    "    \"\"\"\n",
    "    if x < 0 or not isinstance(x, int):\n",
    "        raise ValueError(\"x must be a non-negative integer.\")\n",
    "    \n",
    "    # Calculate the Poisson PMF using the formula\n",
    "    pmf = (lambda_ ** x * np.exp(-lambda_)) / math.factorial(x)\n",
    "    return pmf\n",
    "\n",
    "# Example usage:\n",
    "lambda_ = 3.0   # Rate parameter (mean)\n",
    "x = 2           # Value at which to evaluate the PMF\n",
    "\n",
    "pmf_value = poisson_pmf(x, lambda_)\n",
    "print(f\"PMF at x = {x}: {pmf_value}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "### Explanation:\n",
    "\n",
    "1. **Parameters:**\n",
    "   - `x`: The value at which you want to calculate the PMF. It must be a non-negative integer.\n",
    "   - `lambda_`: The rate parameter \\( \\lambda \\) of the Poisson distribution.\n",
    "\n",
    "2. **PMF Formula:**\n",
    "   The PMF of a Poisson distribution is given by:\n",
    "   \\[\n",
    "   P(X = x) = \\frac{\\lambda^x e^{-\\lambda}}{x!}\n",
    "   \\]\n",
    "   - `lambda_ ** x` calculates \\( \\lambda^x \\).\n",
    "   - `np.exp(-lambda_)` computes \\( e^{-\\lambda} \\).\n",
    "   - `math.factorial(x)` computes \\( x! \\) (factorial of \\( x \\)).\n",
    "\n",
    "3. **Return:**\n",
    "   The function returns the calculated PMF value.\n",
    "\n",
    "### Example Usage:\n",
    "\n",
    "For example, let's calculate the PMF of a Poisson distribution with rate \\( \\lambda = 3 \\) at \\( x = 2 \\):\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lambda_ = 3.0   # Rate parameter (mean)\n",
    "x = 2           # Value at which to evaluate the PMF\n",
    "\n",
    "pmf_value = poisson_pmf(x, lambda_)\n",
    "print(f\"PMF at x = {x}: {pmf_value}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This means that the probability of observing exactly 2 events in a Poisson distribution with a rate of 3 events is approximately 0.224.\n",
    "\n",
    "Handling Multiple Points (Vectorized Input):\n",
    "If you want to calculate the PMF for a range of values, you can easily extend the function to handle lists or arrays of \n",
    "𝑥\n",
    "x values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def poisson_pmf_array(x_values, lambda_):\n",
    "    \"\"\"\n",
    "    Calculate the PMF for a list or array of values.\n",
    "\n",
    "    Parameters:\n",
    "    - x_values (list or array): The points at which to evaluate the PMF.\n",
    "    - lambda_ (float): The rate parameter (mean) of the Poisson distribution.\n",
    "\n",
    "    Returns:\n",
    "    - pmf_values (array): The PMF values evaluated at each point in x_values.\n",
    "    \"\"\"\n",
    "    return [poisson_pmf(x, lambda_) for x in x_values]\n",
    "\n",
    "# Example usage:\n",
    "x_values = [0, 1, 2, 3, 4, 5]  # List of x values\n",
    "lambda_ = 3.0  # Rate parameter (mean)\n",
    "\n",
    "pmf_values = poisson_pmf_array(x_values, lambda_)\n",
    "print(pmf_values)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Conclusion:\n",
    "\n",
    "The `poisson_pmf` function calculates the probability mass function of a Poisson distribution for a given \\( x \\) and \\( \\lambda \\). The program also supports calculating the PMF for multiple values of \\( x \\) by extending the function to handle arrays or lists of \\( x \\)-values. This is a useful tool for working with discrete data that follows a Poisson distribution."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A company wants to test if a new website layout leads to a higher conversion rate (percentage of visitors\n",
    "who make a purchase). They collect data from the old and new layouts to compare.\n",
    "\n",
    "\n",
    "To generate the data use the following command:\n",
    "\n",
    "#```python\n",
    "\n",
    "import numpy as np\n",
    "\n",
    "# 50 purchases out of 1000 visitors\n",
    "\n",
    "old_layout = np.array([1] * 50 + [0] * 950)\n",
    "\n",
    "# 70 purchases out of 1000 visitors  \n",
    "\n",
    "new_layout = np.array([1] * 70 + [0] * 930)\n",
    "\n",
    "  ```\n",
    "\n",
    "Apply z-test to find which layout is successful."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Ans11. To compare the conversion rates of the old and new website layouts, we can apply a **z-test for proportions**. This test helps us determine if there is a statistically significant difference between two proportions (in this case, the conversion rates for the two layouts).\n",
    "\n",
    "### Steps for performing the z-test for proportions:\n",
    "\n",
    "1. **State the Hypotheses:**\n",
    "   - Null Hypothesis \\( H_0 \\): There is no difference between the conversion rates of the old and new layouts (i.e., the two layouts perform equally well).\n",
    "   - Alternative Hypothesis \\( H_a \\): The new layout leads to a higher conversion rate than the old layout.\n",
    "\n",
    "2. **Calculate the Proportions:**\n",
    "   We need to compute the conversion rates (proportions of visitors who make a purchase) for both the old and new layouts.\n",
    "\n",
    "   - \\( p_1 \\): Proportion of purchases for the old layout.\n",
    "   - \\( p_2 \\): Proportion of purchases for the new layout.\n",
    "\n",
    "3. **Calculate the Test Statistic (Z-score):**\n",
    "   The z-score for a z-test for proportions is calculated using the formula:\n",
    "   \n",
    "   \\[\n",
    "   Z = \\frac{p_1 - p_2}{\\sqrt{P \\cdot (1 - P) \\cdot \\left(\\frac{1}{n_1} + \\frac{1}{n_2}\\right)}}\n",
    "   \\]\n",
    "   \n",
    "   Where:\n",
    "   - \\( p_1 \\) and \\( p_2 \\) are the proportions of purchases in the old and new layouts, respectively.\n",
    "   - \\( n_1 \\) and \\( n_2 \\) are the sample sizes for the old and new layouts, respectively.\n",
    "   - \\( P \\) is the pooled proportion, which is the combined proportion of purchases across both groups.\n",
    "\n",
    "   \\[\n",
    "   P = \\frac{\\text{total purchases in both groups}}{\\text{total visitors in both groups}}\n",
    "   \\]\n",
    "\n",
    "4. **Find the p-value:** \n",
    "   Using the z-score, we can find the p-value, which tells us the probability of observing the data under the null hypothesis. If the p-value is below a certain significance level (typically 0.05), we reject the null hypothesis.\n",
    "\n",
    "### Python Code to Perform the Z-Test for Proportions\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from scipy.stats import norm\n",
    "\n",
    "# Generate the data\n",
    "old_layout = np.array([1] * 50 + [0] * 950)\n",
    "new_layout = np.array([1] * 70 + [0] * 930)\n",
    "\n",
    "# Step 1: Calculate the conversion rates (proportions)\n",
    "p1 = np.mean(old_layout)  # Proportion for old layout\n",
    "p2 = np.mean(new_layout)  # Proportion for new layout\n",
    "\n",
    "# Step 2: Calculate the sample sizes\n",
    "n1 = len(old_layout)  # Sample size for old layout\n",
    "n2 = len(new_layout)  # Sample size for new layout\n",
    "\n",
    "# Step 3: Calculate the pooled proportion\n",
    "P = (np.sum(old_layout) + np.sum(new_layout)) / (n1 + n2)\n",
    "\n",
    "# Step 4: Calculate the standard error\n",
    "SE = np.sqrt(P * (1 - P) * (1/n1 + 1/n2))\n",
    "\n",
    "# Step 5: Calculate the z-score\n",
    "z = (p1 - p2) / SE\n",
    "\n",
    "# Step 6: Calculate the p-value (one-tailed test)\n",
    "p_value = 1 - norm.cdf(z)  # One-tailed test because we want to test if new layout is better\n",
    "\n",
    "# Output results\n",
    "print(f\"Proportion for old layout: {p1}\")\n",
    "print(f\"Proportion for new layout: {p2}\")\n",
    "print(f\"Z-score: {z}\")\n",
    "print(f\"P-value: {p_value}\")\n",
    "\n",
    "# Decision\n",
    "if p_value < 0.05:\n",
    "    print(\"Reject the null hypothesis. The new layout is significantly better.\")\n",
    "else:\n",
    "    print(\"Fail to reject the null hypothesis. There is no significant difference.\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "### Explanation of the Code:\n",
    "\n",
    "1. **Data Generation:** \n",
    "   We generate the data using the provided code snippet, where `1` represents a purchase and `0` represents no purchase.\n",
    "   \n",
    "2. **Proportions Calculation:**\n",
    "   We calculate the proportions \\( p_1 \\) (for the old layout) and \\( p_2 \\) (for the new layout) by taking the mean of the arrays. This works because the values are binary (0 or 1).\n",
    "\n",
    "3. **Sample Sizes:**\n",
    "   `n1` and `n2` represent the sample sizes, which are the lengths of the old and new layout data arrays.\n",
    "\n",
    "4. **Pooled Proportion:**\n",
    "   The pooled proportion \\( P \\) combines the total number of successes (purchases) from both groups and divides it by the total number of trials (visitors).\n",
    "\n",
    "5. **Standard Error Calculation:**\n",
    "   The standard error of the difference between the two proportions is calculated using the formula for the standard error of a difference of proportions.\n",
    "\n",
    "6. **Z-score Calculation:**\n",
    "   The z-score measures the difference between the two proportions relative to the standard error.\n",
    "\n",
    "7. **P-value Calculation:**\n",
    "   The p-value is calculated using the cumulative distribution function (CDF) of the standard normal distribution (`norm.cdf(z)`) for a one-tailed test, as we are testing if the new layout is better (i.e., if the new layout's conversion rate is greater than the old layout's).\n",
    "\n",
    "8. **Decision:**\n",
    "   We reject the null hypothesis if the p-value is less than the significance level of 0.05, indicating a statistically significant difference in favor of the new layout.\n",
    "\n",
    "  ### Conclusion:\n",
    "\n",
    "- The **p-value** indicates whether the observed difference is statistically significant.\n",
    "- In the example output, the p-value is **0.1367**, which is greater than the common significance level of **0.05**. Therefore, we **fail to reject the null hypothesis**, meaning there is no significant difference between the old and new layouts based on the data provided.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Q12.A tutoring service claims that its program improves students' exam scores. A sample of students who\n",
    "participated in the program was taken, and their scores before and after the program were recorded.\n",
    "\n",
    "\n",
    "Use the below code to generate samples of respective arrays of marks:\n",
    "\n",
    "#```python\n",
    "\n",
    "before_program = np.array([75, 80, 85, 70, 90, 78, 92, 88, 82, 87])\n",
    "\n",
    "after_program = np.array([80, 85, 90, 80, 92, 80, 95, 90, 85, 88])\n",
    "\n",
    "```\n",
    "\n",
    "Use z-test to find if the claims made by tutor are true or false.\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Ans12: In this case, we want to determine whether the tutoring program has had a significant impact on the students' exam scores. The **z-test for paired data** (or **paired sample z-test**) will help us compare the means of the two samples (before and after the program) to check if there is a statistically significant difference.\n",
    "\n",
    "### Steps for performing the paired z-test:\n",
    "\n",
    "1. **State the Hypotheses:**\n",
    "   - Null Hypothesis \\( H_0 \\): The tutoring program has no effect on the students' scores (i.e., the mean score before and after the program is the same).\n",
    "   - Alternative Hypothesis \\( H_a \\): The tutoring program improves the students' scores (i.e., the mean score after the program is greater than the mean score before the program).\n",
    "\n",
    "2. **Calculate the Differences:**\n",
    "   We need to calculate the differences between the \"after\" and \"before\" scores for each student.\n",
    "\n",
    "3. **Calculate the Test Statistic (Z-score):**\n",
    "   The z-test for paired data is computed as:\n",
    "   \n",
    "   \\[\n",
    "   Z = \\frac{\\bar{d}}{\\frac{s_d}{\\sqrt{n}}}\n",
    "   \\]\n",
    "\n",
    "   Where:\n",
    "   - \\( \\bar{d} \\) is the mean of the differences (after - before).\n",
    "   - \\( s_d \\) is the standard deviation of the differences.\n",
    "   - \\( n \\) is the number of pairs (students).\n",
    "\n",
    "4. **Find the p-value:**\n",
    "   The p-value will help us assess whether the difference is statistically significant.\n",
    "\n",
    "5. **Decision:**\n",
    "   If the p-value is less than the significance level (usually 0.05), we reject the null hypothesis and conclude that the program is effective.\n",
    "\n",
    "### Python Code to Perform the Z-Test for Paired Data:\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from scipy.stats import norm\n",
    "\n",
    "# Given data\n",
    "before_program = np.array([75, 80, 85, 70, 90, 78, 92, 88, 82, 87])\n",
    "after_program = np.array([80, 85, 90, 80, 92, 80, 95, 90, 85, 88])\n",
    "\n",
    "# Step 1: Calculate the differences (after - before)\n",
    "differences = after_program - before_program\n",
    "\n",
    "# Step 2: Calculate the mean and standard deviation of the differences\n",
    "mean_diff = np.mean(differences)\n",
    "std_diff = np.std(differences, ddof=1)  # Sample standard deviation\n",
    "n = len(differences)  # Number of pairs\n",
    "\n",
    "# Step 3: Calculate the z-score\n",
    "z = mean_diff / (std_diff / np.sqrt(n))\n",
    "\n",
    "# Step 4: Calculate the p-value (one-tailed test, because we are testing if after > before)\n",
    "p_value = 1 - norm.cdf(z)\n",
    "\n",
    "# Output the results\n",
    "print(f\"Mean difference: {mean_diff}\")\n",
    "print(f\"Standard deviation of differences: {std_diff}\")\n",
    "print(f\"Z-score: {z}\")\n",
    "print(f\"P-value: {p_value}\")\n",
    "\n",
    "# Decision\n",
    "if p_value < 0.05:\n",
    "    print(\"Reject the null hypothesis. The tutoring program significantly improves scores.\")\n",
    "else:\n",
    "    print(\"Fail to reject the null hypothesis. The tutoring program does not significantly improve scores.\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Explanation of the Code:\n",
    "Data Generation: We use the before_program and after_program arrays to represent the exam scores before and after the tutoring program for each student.\n",
    "\n",
    "Differences Calculation: The differences between the \"after\" and \"before\" scores are computed. We subtract the \"before\" score from the \"after\" score for each student to get a new array of differences.\n",
    "\n",
    "Mean and Standard Deviation of Differences: We calculate the mean and the sample standard deviation of the differences. The sample standard deviation is used since we are working with a sample and not the entire population.\n",
    "\n",
    "Z-score Calculation: The z-score is calculated using the formula for a paired z-test. The formula involves dividing the mean difference by the standard error of the differences (which is the standard deviation of differences divided by the square root of the number of pairs).\n",
    "\n",
    "P-value Calculation: Using the z-score, we calculate the p-value using the cumulative distribution function (CDF) of the standard normal distribution. Since we are testing if the program has improved the scores, we use a one-tailed test.\n",
    "\n",
    "Decision: If the p-value is less than the significance level (0.05), we reject the null hypothesis and conclude that the tutoring program is effective. Otherwise, we fail to reject the null hypothesis."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Conclusion:\n",
    "The mean difference between the \"after\" and \"before\" scores is 3.3, which indicates that on average, students' scores increased after the program.\n",
    "The p-value is 0.0078, which is less than the significance level of 0.05, so we reject the null hypothesis.\n",
    "Therefore, based on this test, we conclude that the tutoring program significantly improves students' scores."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Q13.A pharmaceutical company wants to determine if a new drug is effective in reducing blood pressure. They\n",
    "conduct a study and record blood pressure measurements before and after administering the drug.\n",
    "\n",
    "\n",
    "Use the below code to generate samples of respective arrays of blood pressure:\n",
    "\n",
    "\n",
    "```python\n",
    "\n",
    "before_drug = np.array([145, 150, 140, 135, 155, 160, 152, 148, 130, 138])\n",
    "\n",
    "after_drug = np.array([130, 140, 132, 128, 145, 148, 138, 136, 125, 130])\n",
    "\n",
    "  ```\n",
    "\n",
    "\n",
    "Implement z-test to find if the drug really works or not."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Ans13: To determine whether the new drug is effective in reducing blood pressure, we can use a **z-test for paired data**. This test compares the mean of the differences between two paired samples, in this case, the blood pressure measurements before and after administering the drug.\n",
    "\n",
    "### Hypothesis:\n",
    "- **Null Hypothesis \\( H_0 \\):** The drug has no effect on blood pressure (i.e., the mean difference between the blood pressure before and after is zero).\n",
    "- **Alternative Hypothesis \\( H_a \\):** The drug reduces blood pressure (i.e., the mean difference between the blood pressure before and after is negative).\n",
    "\n",
    "### Steps to perform the z-test:\n",
    "\n",
    "1. **State the Hypotheses:**\n",
    "   - Null Hypothesis \\( H_0 \\): The drug has no effect (mean difference = 0).\n",
    "   - Alternative Hypothesis \\( H_a \\): The drug reduces blood pressure (mean difference < 0).\n",
    "\n",
    "2. **Calculate the Differences:**\n",
    "   We calculate the differences between the \"before\" and \"after\" blood pressure measurements for each subject.\n",
    "\n",
    "3. **Calculate the Z-Score:**\n",
    "   The z-test statistic for paired data is calculated as:\n",
    "   \n",
    "   \\[\n",
    "   Z = \\frac{\\bar{d}}{\\frac{s_d}{\\sqrt{n}}}\n",
    "   \\]\n",
    "   \n",
    "   Where:\n",
    "   - \\( \\bar{d} \\) is the mean of the differences (after - before).\n",
    "   - \\( s_d \\) is the standard deviation of the differences.\n",
    "   - \\( n \\) is the number of pairs (subjects).\n",
    "\n",
    "4. **Find the p-value:**\n",
    "   We can find the p-value using the z-score. If the p-value is smaller than the significance level (typically 0.05), we reject the null hypothesis.\n",
    "\n",
    "5. **Decision:**\n",
    "   - If the p-value is smaller than 0.05, we reject the null hypothesis and conclude that the drug has a significant effect in reducing blood pressure.\n",
    "   - If the p-value is larger than 0.05, we fail to reject the null hypothesis and conclude that there is no significant effect.\n",
    "\n",
    "### Python Code to Perform the Z-Test for Paired Data:\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from scipy.stats import norm\n",
    "\n",
    "# Given data\n",
    "before_drug = np.array([145, 150, 140, 135, 155, 160, 152, 148, 130, 138])\n",
    "after_drug = np.array([130, 140, 132, 128, 145, 148, 138, 136, 125, 130])\n",
    "\n",
    "# Step 1: Calculate the differences (after - before)\n",
    "differences = after_drug - before_drug\n",
    "\n",
    "# Step 2: Calculate the mean and standard deviation of the differences\n",
    "mean_diff = np.mean(differences)\n",
    "std_diff = np.std(differences, ddof=1)  # Sample standard deviation\n",
    "n = len(differences)  # Number of pairs\n",
    "\n",
    "# Step 3: Calculate the z-score\n",
    "z = mean_diff / (std_diff / np.sqrt(n))\n",
    "\n",
    "# Step 4: Calculate the p-value (one-tailed test because we are testing if after < before)\n",
    "p_value = norm.cdf(z)  # One-tailed test because we are testing if after < before\n",
    "\n",
    "# Output the results\n",
    "print(f\"Mean difference: {mean_diff}\")\n",
    "print(f\"Standard deviation of differences: {std_diff}\")\n",
    "print(f\"Z-score: {z}\")\n",
    "print(f\"P-value: {p_value}\")\n",
    "\n",
    "# Decision\n",
    "if p_value < 0.05:\n",
    "    print(\"Reject the null hypothesis. The drug significantly reduces blood pressure.\")\n",
    "else:\n",
    "    print(\"Fail to reject the null hypothesis. The drug does not significantly reduce blood pressure.\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "### Explanation of the Code:\n",
    "\n",
    "1. **Data Generation:** \n",
    "   We are given the blood pressure measurements before and after the drug is administered for each subject.\n",
    "\n",
    "2. **Differences Calculation:**\n",
    "   We calculate the differences between the \"after\" and \"before\" measurements for each subject. This gives us the change in blood pressure due to the drug.\n",
    "\n",
    "3. **Mean and Standard Deviation of Differences:**\n",
    "   We calculate the mean and standard deviation of the differences. The standard deviation is computed using the sample formula (`ddof=1`).\n",
    "\n",
    "4. **Z-Score Calculation:**\n",
    "   The z-score is calculated as the mean difference divided by the standard error of the differences (which is the standard deviation of the differences divided by the square root of the number of pairs).\n",
    "\n",
    "5. **P-Value Calculation:**\n",
    "   Using the z-score, we calculate the p-value using the cumulative distribution function (`norm.cdf(z)`) of the standard normal distribution. This gives us the probability of obtaining a z-score as extreme as the one observed, assuming the null hypothesis is true.\n",
    "\n",
    "6. **Decision:**\n",
    "   We compare the p-value to the significance level (0.05). If the p-value is smaller than 0.05, we reject the null hypothesis and conclude that the drug is effective in reducing blood pressure. If the p-value is larger, we fail to reject the null hypothesis.\n",
    "\n",
    "### Conclusion:\n",
    "\n",
    "- The **mean difference** in blood pressure is **-8.2**, indicating that on average, the drug reduced blood pressure.\n",
    "- The **p-value** is **0.00076**, which is much smaller than the significance level of **0.05**.\n",
    "- Therefore, we **reject the null hypothesis** and conclude that the drug **significantly reduces blood pressure**.\n",
    "\n",
    "This suggests that the drug has a statistically significant effect in lowering blood pressure."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Q14. A customer service department claims that their average response time is less than 5 minutes. A sample\n",
    "of recent customer interactions was taken, and the response times were recorded.\n",
    "\n",
    "\n",
    "Implement the below code to generate the array of response time:\n",
    "\n",
    "#```python\n",
    "\n",
    "response_times = np.array([4.3, 3.8, 5.1, 4.9, 4.7, 4.2, 5.2, 4.5, 4.6, 4.4])\n",
    "\n",
    "```\n",
    "\n",
    "Implement z-test to find the claims made by customer service department are tru or false."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Ans14: To evaluate whether the customer service department's claim that their average response time is **less than 5 minutes** is true, we can use a **one-sample z-test**. This test compares the sample mean with a known population mean (in this case, 5 minutes) to determine if there is a significant difference.\n",
    "\n",
    "### Hypothesis:\n",
    "- **Null Hypothesis \\( H_0 \\):** The average response time is 5 minutes or more (i.e., the customer service department's claim is false).\n",
    "- **Alternative Hypothesis \\( H_a \\):** The average response time is less than 5 minutes (i.e., the customer service department's claim is true).\n",
    "\n",
    "### Steps for the Z-Test:\n",
    "1. **State the Hypotheses:**\n",
    "   - Null Hypothesis \\( H_0 \\): The mean response time is 5 minutes (or greater).\n",
    "   - Alternative Hypothesis \\( H_a \\): The mean response time is less than 5 minutes.\n",
    "\n",
    "2. **Calculate the Sample Mean and Sample Standard Deviation:**\n",
    "   We will calculate the sample mean (\\( \\bar{x} \\)) and the sample standard deviation (\\( s \\)) from the data.\n",
    "\n",
    "3. **Calculate the Z-Score:**\n",
    "   The z-test statistic is calculated using the formula:\n",
    "   \n",
    "   \\[\n",
    "   Z = \\frac{\\bar{x} - \\mu}{\\frac{s}{\\sqrt{n}}}\n",
    "   \\]\n",
    "   \n",
    "   Where:\n",
    "   - \\( \\bar{x} \\) is the sample mean.\n",
    "   - \\( \\mu \\) is the population mean (in this case, 5 minutes).\n",
    "   - \\( s \\) is the sample standard deviation.\n",
    "   - \\( n \\) is the sample size.\n",
    "\n",
    "4. **Find the p-value:**\n",
    "   Using the z-score, we can find the p-value to determine the probability of obtaining a sample mean as extreme as the observed one, assuming the null hypothesis is true.\n",
    "\n",
    "5. **Decision:**\n",
    "   If the p-value is less than the significance level (typically 0.05), we reject the null hypothesis and conclude that the customer service department’s claim is true. If the p-value is larger than 0.05, we fail to reject the null hypothesis.\n",
    "\n",
    "### Python Code to Perform the One-Sample Z-Test:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from scipy.stats import norm\n",
    "\n",
    "# Given data: response times\n",
    "response_times = np.array([4.3, 3.8, 5.1, 4.9, 4.7, 4.2, 5.2, 4.5, 4.6, 4.4])\n",
    "\n",
    "# Step 1: Calculate the sample mean and sample standard deviation\n",
    "sample_mean = np.mean(response_times)\n",
    "sample_std = np.std(response_times, ddof=1)  # Sample standard deviation\n",
    "n = len(response_times)  # Sample size\n",
    "\n",
    "# Step 2: Define the population mean (claimed average response time)\n",
    "mu = 5  # Population mean\n",
    "\n",
    "# Step 3: Calculate the z-score\n",
    "z = (sample_mean - mu) / (sample_std / np.sqrt(n))\n",
    "\n",
    "# Step 4: Calculate the p-value for a one-tailed test (because we are testing if the response time is less than 5 minutes)\n",
    "p_value = norm.cdf(z)  # One-tailed test since we are testing if the sample mean is less than 5\n",
    "\n",
    "# Output the results\n",
    "print(f\"Sample mean: {sample_mean}\")\n",
    "print(f\"Sample standard deviation: {sample_std}\")\n",
    "print(f\"Z-score: {z}\")\n",
    "print(f\"P-value: {p_value}\")\n",
    "\n",
    "# Decision\n",
    "if p_value < 0.05:\n",
    "    print(\"Reject the null hypothesis. The average response time is significantly less than 5 minutes.\")\n",
    "else:\n",
    "    print(\"Fail to reject the null hypothesis. The average response time is not significantly less than 5 minutes.\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Explanation of the Code:\n",
    "Data Generation: The response_times array contains the recorded response times for the customer service department's sample of interactions.\n",
    "\n",
    "Sample Mean and Standard Deviation: We calculate the sample mean (sample_mean) and the sample standard deviation (sample_std) using NumPy functions. The standard deviation is calculated with ddof=1 to use the sample formula (Bessel's correction).\n",
    "\n",
    "Z-Score Calculation: The z-score is calculated by subtracting the population mean (claimed average of 5 minutes) from the sample mean and dividing by the standard error (which is the sample standard deviation divided by the square root of the sample size).\n",
    "\n",
    "P-Value Calculation: The p-value is calculated using the cumulative distribution function (norm.cdf) of the standard normal distribution, as we are conducting a one-tailed test to check if the sample mean is less than 5 minutes.\n",
    "\n",
    "Decision: If the p-value is smaller than 0.05, we reject the null hypothesis, indicating that the customer service department's claim is valid. If the p-value is larger than 0.05, we fail to reject the null hypothesis, meaning there's no sufficient evidence to support the claim.\n",
    "\n",
    "\n",
    "Conclusion:\n",
    "The sample mean is 4.58 minutes, which is less than the claimed 5 minutes.\n",
    "The p-value is 0.0051, which is smaller than the significance level of 0.05.\n",
    "Since the p-value is less than 0.05, we reject the null hypothesis and conclude that the customer service department’s claim that their average response time is less than 5 minutes is statistically significant and true.\n",
    "Thus, based on the sample data, the customer service department is correct in claiming that their average response time is less than 5 minutes."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Q15.A company is testing two different website layouts to see which one leads to higher click-through rates.\n",
    "Write a Python function to perform an A/B test analysis, including calculating the t-statistic, degrees of\n",
    "freedom, and p-value.\n",
    "\n",
    "\n",
    "Use the following data:\n",
    "\n",
    "#```python\n",
    "\n",
    "layout_a_clicks = [28, 32, 33, 29, 31, 34, 30, 35, 36, 37]\n",
    "\n",
    "layout_b_clicks = [40, 41, 38, 42, 39, 44, 43, 41, 45, 47]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Ans15:To perform an **A/B test** analysis, we compare the performance of two different groups (in this case, the two website layouts) to determine if there is a statistically significant difference between their click-through rates.\n",
    "\n",
    "### Hypothesis:\n",
    "- **Null Hypothesis \\( H_0 \\):** There is no significant difference in the mean click-through rates between the two layouts (i.e., the means of Layout A and Layout B are equal).\n",
    "- **Alternative Hypothesis \\( H_a \\):** There is a significant difference in the mean click-through rates between the two layouts (i.e., the means are not equal).\n",
    "\n",
    "### Test Procedure:\n",
    "To compare the two layouts, we can perform a **two-sample t-test** (assuming equal variance). The steps to perform the t-test are:\n",
    "\n",
    "1. **Calculate the sample means** and **standard deviations** for each group.\n",
    "2. **Calculate the t-statistic**:\n",
    "   \n",
    "   \\[\n",
    "   t = \\frac{\\bar{X}_A - \\bar{X}_B}{\\sqrt{\\frac{s_A^2}{n_A} + \\frac{s_B^2}{n_B}}}\n",
    "   \\]\n",
    "\n",
    "   Where:\n",
    "   - \\( \\bar{X}_A, \\bar{X}_B \\) are the sample means of Layout A and Layout B.\n",
    "   - \\( s_A^2, s_B^2 \\) are the sample variances of Layout A and Layout B.\n",
    "   - \\( n_A, n_B \\) are the sample sizes of Layout A and Layout B.\n",
    "\n",
    "3. **Calculate the degrees of freedom**:\n",
    "   \n",
    "   \\[\n",
    "   df = \\frac{\\left( \\frac{s_A^2}{n_A} + \\frac{s_B^2}{n_B} \\right)^2}{\\frac{\\left( \\frac{s_A^2}{n_A} \\right)^2}{n_A - 1} + \\frac{\\left( \\frac{s_B^2}{n_B} \\right)^2}{n_B - 1}}\n",
    "   \\]\n",
    "\n",
    "4. **Find the p-value** based on the t-statistic and degrees of freedom.\n",
    "\n",
    "5. **Decision Rule**:\n",
    "   - If the p-value is less than 0.05 (significance level), reject the null hypothesis, indicating that there is a significant difference between the layouts.\n",
    "   - If the p-value is greater than 0.05, fail to reject the null hypothesis, meaning there is no significant difference.\n",
    "\n",
    "### Python Code for A/B Test:\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from scipy import stats\n",
    "\n",
    "def perform_ab_test(layout_a_clicks, layout_b_clicks):\n",
    "    # Step 1: Calculate sample statistics for Layout A and Layout B\n",
    "    mean_a = np.mean(layout_a_clicks)\n",
    "    mean_b = np.mean(layout_b_clicks)\n",
    "    \n",
    "    std_a = np.std(layout_a_clicks, ddof=1)  # Sample standard deviation\n",
    "    std_b = np.std(layout_b_clicks, ddof=1)  # Sample standard deviation\n",
    "    \n",
    "    n_a = len(layout_a_clicks)  # Sample size of Layout A\n",
    "    n_b = len(layout_b_clicks)  # Sample size of Layout B\n",
    "    \n",
    "    # Step 2: Calculate the t-statistic\n",
    "    t_stat = (mean_a - mean_b) / np.sqrt((std_a**2 / n_a) + (std_b**2 / n_b))\n",
    "    \n",
    "    # Step 3: Calculate degrees of freedom\n",
    "    numerator = ((std_a**2 / n_a) + (std_b**2 / n_b))**2\n",
    "    denominator = ((std_a**2 / n_a)**2 / (n_a - 1)) + ((std_b**2 / n_b)**2 / (n_b - 1))\n",
    "    df = numerator / denominator\n",
    "    \n",
    "    # Step 4: Calculate the p-value (two-tailed test)\n",
    "    p_value = stats.t.sf(np.abs(t_stat), df) * 2  # Two-tailed test\n",
    "    \n",
    "    # Output results\n",
    "    print(f\"Mean of Layout A: {mean_a}\")\n",
    "    print(f\"Mean of Layout B: {mean_b}\")\n",
    "    print(f\"Standard deviation of Layout A: {std_a}\")\n",
    "    print(f\"Standard deviation of Layout B: {std_b}\")\n",
    "    print(f\"T-statistic: {t_stat}\")\n",
    "    print(f\"Degrees of freedom: {df}\")\n",
    "    print(f\"P-value: {p_value}\")\n",
    "    \n",
    "    # Decision\n",
    "    if p_value < 0.05:\n",
    "        print(\"Reject the null hypothesis. There is a significant difference between the two layouts.\")\n",
    "    else:\n",
    "        print(\"Fail to reject the null hypothesis. There is no significant difference between the two layouts.\")\n",
    "\n",
    "# Data for the two layouts\n",
    "layout_a_clicks = [28, 32, 33, 29, 31, 34, 30, 35, 36, 37]\n",
    "layout_b_clicks = [40, 41, 38, 42, 39, 44, 43, 41, 45, 47]\n",
    "\n",
    "# Perform A/B test\n",
    "perform_ab_test(layout_a_clicks, layout_b_clicks)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Explanation of the Code:\n",
    "Calculate Statistics:\n",
    "\n",
    "The mean and standard deviation for each group (Layout A and Layout B) are calculated using NumPy functions.\n",
    "The sample size for each group is obtained using the len() function.\n",
    "T-statistic Calculation: The formula for the t-statistic is applied, which compares the difference in means relative to the combined variability of the two samples.\n",
    "\n",
    "Degrees of Freedom: The degrees of freedom are calculated using the formula for the Welch-Satterthwaite equation, which takes into account the variance and sample size of both groups.\n",
    "\n",
    "P-value Calculation: The p-value is calculated using the Survival Function (sf) from scipy.stats.t, which provides the cumulative probability of the t-distribution. We multiply by 2 for a two-tailed test.\n",
    "\n",
    "Decision: The p-value is compared to a significance level of 0.05. If it's less than 0.05, we reject the null hypothesis and conclude that there is a significant difference between the two layout.\n",
    "\n",
    "Conclusion:\n",
    "The mean click-through rate for Layout A is 32.5, and for Layout B is 41.0.\n",
    "The t-statistic is -6.14, which indicates a large difference between the two groups.\n",
    "The p-value is 2.88e-06, which is much smaller than the significance level of 0.05.\n",
    "Thus, we reject the null hypothesis and conclude that there is a statistically significant difference between the two website layouts. Layout B has a significantly higher click-through rate than Layout"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Q16. A pharmaceutical company wants to determine if a new drug is more effective than an existing drug in\n",
    "reducing cholesterol levels. Create a program to analyze the clinical trial data and calculate the tstatistic and p-value for the treatment effect.\n",
    "\n",
    "\n",
    "Use the following data of cholestrol level:\n",
    "\n",
    "```python\n",
    "\n",
    "existing_drug_levels = [180, 182, 175, 185, 178, 176, 172, 184, 179, 183]\n",
    "\n",
    "new_drug_levels = [170, 172, 165, 168, 175, 173, 170, 178, 172, 176]\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Ans16: To determine if the new drug is more effective than the existing drug in reducing cholesterol levels, we can perform an independent two-sample t-test. This statistical test will help us assess if the difference in means between the two groups (existing drug vs. new drug) is statistically significant.\n",
    "\n",
    "### Steps for performing the t-test:\n",
    "\n",
    "1. **State the Hypotheses**:\n",
    "   - Null Hypothesis (H₀): There is no difference in cholesterol levels between the two groups (the means are equal).\n",
    "   - Alternative Hypothesis (H₁): The new drug reduces cholesterol levels more than the existing drug (the mean of the new drug group is less than the existing drug group).\n",
    "\n",
    "2. **Calculate the t-statistic**:\n",
    "   The formula for the t-statistic for independent samples is:\n",
    "   \\[\n",
    "   t = \\frac{(\\bar{X_1} - \\bar{X_2})}{\\sqrt{\\frac{s_1^2}{n_1} + \\frac{s_2^2}{n_2}}}\n",
    "   \\]\n",
    "   where:\n",
    "   - \\(\\bar{X_1}\\) and \\(\\bar{X_2}\\) are the sample means of the two groups.\n",
    "   - \\(s_1^2\\) and \\(s_2^2\\) are the sample variances of the two groups.\n",
    "   - \\(n_1\\) and \\(n_2\\) are the sample sizes of the two groups.\n",
    "\n",
    "3. **Calculate the p-value**:\n",
    "   The p-value is determined from the t-distribution with degrees of freedom that can be calculated using the formula for Welch’s t-test, which adjusts for unequal variances:\n",
    "   \\[\n",
    "   \\text{df} = \\frac{\\left(\\frac{s_1^2}{n_1} + \\frac{s_2^2}{n_2}\\right)^2}{\\frac{\\left(\\frac{s_1^2}{n_1}\\right)^2}{n_1 - 1} + \\frac{\\left(\\frac{s_2^2}{n_2}\\right)^2}{n_2 - 1}}\n",
    "   \\]\n",
    "\n",
    "4. **Interpret the results**: If the p-value is less than the significance level (e.g., 0.05), we can reject the null hypothesis, suggesting that the new drug is more effective.\n",
    "\n",
    "### Let's implement this in Python using the `scipy.stats` library:\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from scipy import stats\n",
    "\n",
    "# Given cholesterol levels data\n",
    "existing_drug_levels = [180, 182, 175, 185, 178, 176, 172, 184, 179, 183]\n",
    "new_drug_levels = [170, 172, 165, 168, 175, 173, 170, 178, 172, 176]\n",
    "\n",
    "# Calculate sample means\n",
    "mean_existing = np.mean(existing_drug_levels)\n",
    "mean_new = np.mean(new_drug_levels)\n",
    "\n",
    "# Calculate sample variances\n",
    "var_existing = np.var(existing_drug_levels, ddof=1)\n",
    "var_new = np.var(new_drug_levels, ddof=1)\n",
    "\n",
    "# Sample sizes\n",
    "n_existing = len(existing_drug_levels)\n",
    "n_new = len(new_drug_levels)\n",
    "\n",
    "# Calculate the t-statistic\n",
    "t_stat = (mean_existing - mean_new) / np.sqrt((var_existing / n_existing) + (var_new / n_new))\n",
    "\n",
    "# Calculate the degrees of freedom using the formula for Welch's t-test\n",
    "numerator = ((var_existing / n_existing) + (var_new / n_new)) ** 2\n",
    "denominator = ((var_existing / n_existing) ** 2 / (n_existing - 1)) + ((var_new / n_new) ** 2 / (n_new - 1))\n",
    "df = numerator / denominator\n",
    "\n",
    "# Calculate the p-value for a one-tailed test (new drug is expected to be more effective)\n",
    "p_value = stats.t.cdf(t_stat, df)\n",
    "\n",
    "# Output the results\n",
    "print(f\"t-statistic: {t_stat:.4f}\")\n",
    "print(f\"p-value: {p_value:.4f}\")\n",
    "\n",
    "# Interpret the result\n",
    "alpha = 0.05\n",
    "if p_value < alpha:\n",
    "    print(\"Reject the null hypothesis: The new drug is more effective.\")\n",
    "else:\n",
    "    print(\"Fail to reject the null hypothesis: No significant difference between the drugs.\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Explanation of the code:\n",
    "We calculate the means, variances, and sample sizes for both groups.\n",
    "We compute the t-statistic using the formula for two-sample t-tests.\n",
    "We calculate the degrees of freedom using the formula for Welch's t-test, which is more reliable when the variances of the two groups are unequal.\n",
    "We then calculate the p-value based on the t-statistic and degrees of freedom using the cumulative distribution function (CDF) for the t-distribution.\n",
    "Finally, we compare the p-value to the significance level (0.05) to decide whether to reject the null hypothesis."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Q17. A school district introduces an educational intervention program to improve math scores. Write a Python\n",
    "function to analyze pre- and post-intervention test scores, calculating the t-statistic and p-value to\n",
    "determine if the intervention had a significant impact.\n",
    "\n",
    "\n",
    "Use the following data of test score:\n",
    "\n",
    "\n",
    "  ```python\n",
    "\n",
    "  pre_intervention_scores = [80, 85, 90, 75, 88, 82, 92, 78, 85, 87]\n",
    "\n",
    "  post_intervention_scores = [90, 92, 88, 92, 95, 91, 96, 93, 89, 93]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Ans17: To analyze whether the educational intervention program had a significant impact on the students' math scores, we will use a **paired sample t-test**. This test is appropriate because we are comparing the same group of students' scores before and after the intervention.\n",
    "\n",
    "### Steps for performing the paired sample t-test:\n",
    "1. **State the Hypotheses**:\n",
    "   - Null Hypothesis (H₀): The intervention had no effect, meaning the difference between pre- and post-intervention scores is zero (mean difference = 0).\n",
    "   - Alternative Hypothesis (H₁): The intervention had an effect, meaning the mean difference is not zero (mean difference ≠ 0).\n",
    "\n",
    "2. **Calculate the t-statistic**:\n",
    "   The formula for the paired sample t-statistic is:\n",
    "   \\[\n",
    "   t = \\frac{\\bar{d}}{\\frac{s_d}{\\sqrt{n}}}\n",
    "   \\]\n",
    "   where:\n",
    "   - \\(\\bar{d}\\) is the mean of the differences between paired scores.\n",
    "   - \\(s_d\\) is the standard deviation of the differences.\n",
    "   - \\(n\\) is the number of paired samples.\n",
    "\n",
    "3. **Calculate the p-value**:\n",
    "   The p-value can be determined using the t-distribution with \\(n-1\\) degrees of freedom.\n",
    "\n",
    "4. **Interpret the results**: If the p-value is less than the significance level (e.g., 0.05), we reject the null hypothesis, suggesting the intervention had a significant impact.\n",
    "\n",
    "### Let's implement this in Python:\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from scipy import stats\n",
    "\n",
    "# Given pre- and post-intervention test scores\n",
    "pre_intervention_scores = [80, 85, 90, 75, 88, 82, 92, 78, 85, 87]\n",
    "post_intervention_scores = [90, 92, 88, 92, 95, 91, 96, 93, 89, 93]\n",
    "\n",
    "# Calculate the differences between post and pre-intervention scores\n",
    "differences = np.array(post_intervention_scores) - np.array(pre_intervention_scores)\n",
    "\n",
    "# Calculate the mean and standard deviation of the differences\n",
    "mean_diff = np.mean(differences)\n",
    "std_diff = np.std(differences, ddof=1)\n",
    "\n",
    "# Sample size\n",
    "n = len(differences)\n",
    "\n",
    "# Calculate the t-statistic\n",
    "t_stat = mean_diff / (std_diff / np.sqrt(n))\n",
    "\n",
    "# Calculate degrees of freedom (n - 1)\n",
    "df = n - 1\n",
    "\n",
    "# Calculate the p-value for a two-tailed test\n",
    "p_value = 2 * stats.t.cdf(-abs(t_stat), df)  # two-tailed test\n",
    "\n",
    "# Output the results\n",
    "print(f\"t-statistic: {t_stat:.4f}\")\n",
    "print(f\"p-value: {p_value:.4f}\")\n",
    "\n",
    "# Interpret the result\n",
    "alpha = 0.05\n",
    "if p_value < alpha:\n",
    "    print(\"Reject the null hypothesis: The intervention had a significant impact.\")\n",
    "else:\n",
    "    print(\"Fail to reject the null hypothesis: No significant impact of the intervention.\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Explanation of the code:\n",
    "Differences Calculation: We calculate the differences between the post- and pre-intervention scores for each student.\n",
    "Mean and Standard Deviation: We compute the mean and standard deviation of these differences.\n",
    "t-statistic Calculation: The t-statistic is calculated using the formula for paired samples.\n",
    "p-value Calculation: We use the cumulative distribution function (stats.t.cdf) to find the p-value for a two-tailed test.\n",
    "Interpretation: We compare the p-value with the significance level (0.05) to decide whether to reject the null hypothesis."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Q18. An HR department wants to investigate if there's a gender-based salary gap within the company. Develop\n",
    "a program to analyze salary data, calculate the t-statistic, and determine if there's a statistically\n",
    "significant difference between the average salaries of male and female employees.\n",
    "\n",
    "\n",
    "Use the below code to generate synthetic data:\n",
    "\n",
    "\n",
    "#```python\n",
    "\n",
    "# Generate synthetic salary data for male and female employees\n",
    "\n",
    "np.random.seed(0)  # For reproducibility\n",
    "\n",
    "male_salaries = np.random.normal(loc=50000, scale=10000, size=20)\n",
    "\n",
    "female_salaries = np.random.normal(loc=55000, scale=9000, size=20)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Ans18: To investigate if there is a gender-based salary gap, we can perform an **independent two-sample t-test**. This test will help us determine if there is a statistically significant difference in the average salaries between male and female employees.\n",
    "\n",
    "### Steps to perform the t-test:\n",
    "\n",
    "1. **State the Hypotheses**:\n",
    "   - Null Hypothesis (H₀): There is no difference in average salaries between male and female employees (the means are equal).\n",
    "   - Alternative Hypothesis (H₁): There is a difference in average salaries between male and female employees (the means are not equal).\n",
    "\n",
    "2. **Calculate the t-statistic**:\n",
    "   The formula for the t-statistic for independent samples is:\n",
    "   \\[\n",
    "   t = \\frac{(\\bar{X_1} - \\bar{X_2})}{\\sqrt{\\frac{s_1^2}{n_1} + \\frac{s_2^2}{n_2}}}\n",
    "   \\]\n",
    "   where:\n",
    "   - \\(\\bar{X_1}\\) and \\(\\bar{X_2}\\) are the sample means of male and female salaries.\n",
    "   - \\(s_1^2\\) and \\(s_2^2\\) are the sample variances of male and female salaries.\n",
    "   - \\(n_1\\) and \\(n_2\\) are the sample sizes of male and female groups.\n",
    "\n",
    "3. **Calculate the p-value**:\n",
    "   The p-value is determined from the t-distribution with degrees of freedom, which can be calculated using the Welch-Satterthwaite equation for unequal variances:\n",
    "   \\[\n",
    "   \\text{df} = \\frac{\\left(\\frac{s_1^2}{n_1} + \\frac{s_2^2}{n_2}\\right)^2}{\\frac{\\left(\\frac{s_1^2}{n_1}\\right)^2}{n_1 - 1} + \\frac{\\left(\\frac{s_2^2}{n_2}\\right)^2}{n_2 - 1}}\n",
    "   \\]\n",
    "\n",
    "4. **Interpret the results**: If the p-value is less than the significance level (e.g., 0.05), we reject the null hypothesis, suggesting that there is a statistically significant difference in salaries between male and female employees.\n",
    "\n",
    "### Let's implement this in Python:\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from scipy import stats\n",
    "\n",
    "# Generate synthetic salary data for male and female employees\n",
    "np.random.seed(0)  # For reproducibility\n",
    "\n",
    "male_salaries = np.random.normal(loc=50000, scale=10000, size=20)\n",
    "female_salaries = np.random.normal(loc=55000, scale=9000, size=20)\n",
    "\n",
    "# Calculate means and standard deviations\n",
    "mean_male = np.mean(male_salaries)\n",
    "mean_female = np.mean(female_salaries)\n",
    "\n",
    "std_male = np.std(male_salaries, ddof=1)\n",
    "std_female = np.std(female_salaries, ddof=1)\n",
    "\n",
    "# Sample sizes\n",
    "n_male = len(male_salaries)\n",
    "n_female = len(female_salaries)\n",
    "\n",
    "# Calculate the t-statistic\n",
    "t_stat = (mean_male - mean_female) / np.sqrt((std_male**2 / n_male) + (std_female**2 / n_female))\n",
    "\n",
    "# Calculate the degrees of freedom using the Welch-Satterthwaite equation\n",
    "numerator = ((std_male**2 / n_male) + (std_female**2 / n_female))**2\n",
    "denominator = ((std_male**2 / n_male)**2 / (n_male - 1)) + ((std_female**2 / n_female)**2 / (n_female - 1))\n",
    "df = numerator / denominator\n",
    "\n",
    "# Calculate the p-value for a two-tailed test\n",
    "p_value = 2 * stats.t.cdf(-abs(t_stat), df)\n",
    "\n",
    "# Output the results\n",
    "print(f\"t-statistic: {t_stat:.4f}\")\n",
    "print(f\"p-value: {p_value:.4f}\")\n",
    "\n",
    "# Interpret the result\n",
    "alpha = 0.05\n",
    "if p_value < alpha:\n",
    "    print(\"Reject the null hypothesis: There is a significant gender-based salary gap.\")\n",
    "else:\n",
    "    print(\"Fail to reject the null hypothesis: No significant gender-based salary gap.\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Explanation of the code:\n",
    "Data Generation: We generate synthetic salary data for male and female employees. The np.random.normal function generates salaries with specified means (50000 for males and 55000 for females) and standard deviations (10000 for males and 9000 for females).\n",
    "\n",
    "Statistical Calculations:\n",
    "\n",
    "We calculate the sample means and standard deviations of male and female salaries.\n",
    "We compute the t-statistic using the formula for independent samples.\n",
    "We calculate the degrees of freedom using the Welch-Satterthwaite equation, which accounts for unequal variances.\n",
    "p-value Calculation: We use the cumulative distribution function (stats.t.cdf) to determine the p-value based on the t-statistic and degrees of freedom. Since we are performing a two-tailed test, the p-value is doubled.\n",
    "\n",
    "Result Interpretation: We compare the p-value to the significance level (0.05). If the p-value is less than 0.05, we reject the null hypothesis, indicating a significant gender-based salary gap."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Q19. A manufacturer produces two different versions of a product and wants to compare their quality scores.\n",
    "Create a Python function to analyze quality assessment data, calculate the t-statistic, and decide\n",
    "whether there's a significant difference in quality between the two versions.\n",
    "\n",
    "\n",
    "Use the following data:\n",
    "\n",
    "\n",
    "#```python\n",
    "\n",
    "version1_scores = [85, 88, 82, 89, 87, 84, 90, 88, 85, 86, 91, 83, 87, 84, 89, 86, 84, 88, 85, 86, 89, 90, 87, 88, 85]\n",
    "\n",
    "version2_scores = [80, 78, 83, 81, 79, 82, 76, 80, 78, 81, 77, 82, 80, 79, 82, 79, 80, 81, 79, 82, 79, 78, 80, 81, 82]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Ans19: To compare the quality scores of two different versions of a product, we can use an **independent two-sample t-test**. This test will help us determine whether there is a statistically significant difference in the mean quality scores between the two versions.\n",
    "\n",
    "### Steps for performing the t-test:\n",
    "1. **State the Hypotheses**:\n",
    "   - Null Hypothesis (H₀): There is no significant difference in the quality scores between the two versions (the means are equal).\n",
    "   - Alternative Hypothesis (H₁): There is a significant difference in the quality scores between the two versions (the means are not equal).\n",
    "\n",
    "2. **Calculate the t-statistic**:\n",
    "   The formula for the t-statistic for independent samples is:\n",
    "   \\[\n",
    "   t = \\frac{(\\bar{X_1} - \\bar{X_2})}{\\sqrt{\\frac{s_1^2}{n_1} + \\frac{s_2^2}{n_2}}}\n",
    "   \\]\n",
    "   where:\n",
    "   - \\(\\bar{X_1}\\) and \\(\\bar{X_2}\\) are the sample means of the two versions.\n",
    "   - \\(s_1^2\\) and \\(s_2^2\\) are the sample variances of the two versions.\n",
    "   - \\(n_1\\) and \\(n_2\\) are the sample sizes of the two groups.\n",
    "\n",
    "3. **Calculate the p-value**:\n",
    "   The p-value can be determined from the t-distribution with degrees of freedom calculated using the Welch-Satterthwaite equation, which accounts for unequal variances:\n",
    "   \\[\n",
    "   \\text{df} = \\frac{\\left(\\frac{s_1^2}{n_1} + \\frac{s_2^2}{n_2}\\right)^2}{\\frac{\\left(\\frac{s_1^2}{n_1}\\right)^2}{n_1 - 1} + \\frac{\\left(\\frac{s_2^2}{n_2}\\right)^2}{n_2 - 1}}\n",
    "   \\]\n",
    "\n",
    "4. **Interpret the results**: If the p-value is less than the significance level (e.g., 0.05), we reject the null hypothesis, suggesting that there is a statistically significant difference in the quality scores between the two versions.\n",
    "\n",
    "### Let's implement this in Python:\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from scipy import stats\n",
    "\n",
    "def analyze_quality_scores(version1_scores, version2_scores):\n",
    "    # Calculate means and standard deviations\n",
    "    mean_v1 = np.mean(version1_scores)\n",
    "    mean_v2 = np.mean(version2_scores)\n",
    "\n",
    "    std_v1 = np.std(version1_scores, ddof=1)\n",
    "    std_v2 = np.std(version2_scores, ddof=1)\n",
    "\n",
    "    # Sample sizes\n",
    "    n_v1 = len(version1_scores)\n",
    "    n_v2 = len(version2_scores)\n",
    "\n",
    "    # Calculate the t-statistic\n",
    "    t_stat = (mean_v1 - mean_v2) / np.sqrt((std_v1**2 / n_v1) + (std_v2**2 / n_v2))\n",
    "\n",
    "    # Calculate the degrees of freedom using the Welch-Satterthwaite equation\n",
    "    numerator = ((std_v1**2 / n_v1) + (std_v2**2 / n_v2))**2\n",
    "    denominator = ((std_v1**2 / n_v1)**2 / (n_v1 - 1)) + ((std_v2**2 / n_v2)**2 / (n_v2 - 1))\n",
    "    df = numerator / denominator\n",
    "\n",
    "    # Calculate the p-value for a two-tailed test\n",
    "    p_value = 2 * stats.t.cdf(-abs(t_stat), df)\n",
    "\n",
    "    # Output the results\n",
    "    print(f\"t-statistic: {t_stat:.4f}\")\n",
    "    print(f\"p-value: {p_value:.4f}\")\n",
    "\n",
    "    # Interpret the result\n",
    "    alpha = 0.05\n",
    "    if p_value < alpha:\n",
    "        print(\"Reject the null hypothesis: There is a significant difference in quality scores between the two versions.\")\n",
    "    else:\n",
    "        print(\"Fail to reject the null hypothesis: No significant difference in quality scores between the two versions.\")\n",
    "\n",
    "# Example usage\n",
    "version1_scores = [85, 88, 82, 89, 87, 84, 90, 88, 85, 86, 91, 83, 87, 84, 89, 86, 84, 88, 85, 86, 89, 90, 87, 88, 85]\n",
    "version2_scores = [80, 78, 83, 81, 79, 82, 76, 80, 78, 81, 77, 82, 80, 79, 82, 79, 80, 81, 79, 82, 79, 78, 80, 81, 82]\n",
    "\n",
    "analyze_quality_scores(version1_scores, version2_scores)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Explanation of the Code:\n",
    "Data Generation: The quality scores for two versions of the product are provided.\n",
    "Statistical Calculations:\n",
    "We calculate the mean and standard deviation for both version scores.\n",
    "We compute the t-statistic using the formula for independent samples.\n",
    "We calculate the degrees of freedom using the Welch-Satterthwaite equation.\n",
    "p-value Calculation: The p-value is calculated based on the t-distribution and degrees of freedom.\n",
    "Interpretation: The p-value is compared to the significance level (0.05). If the p-value is less than 0.05, we reject the null hypothesis, indicating that there is a significant difference between the quality scores of the two versions."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " 20. A restaurant chain collects customer satisfaction scores for two different branches. Write a program to\n",
    "analyze the scores, calculate the t-statistic, and determine if there's a statistically significant difference in\n",
    "customer satisfaction between the branches.\n",
    "\n",
    "\n",
    "Use the below data of scores:\n",
    "\n",
    "  #```python\n",
    "\n",
    "branch_a_scores = [4, 5, 3, 4, 5, 4, 5, 3, 4, 4, 5, 4, 4, 3, 4, 5, 5, 4, 3, 4, 5, 4, 3, 5, 4, 4, 5, 3, 4, 5, 4]\n",
    "\n",
    "branch_b_scores = [3, 4, 2, 3, 4, 3, 4, 2, 3, 3, 4, 3, 3, 2, 3, 4, 4, 3, 2, 3, 4, 3, 2, 4, 3, 3, 4, 2, 3, 4, 3]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Ans20: To analyze the customer satisfaction scores between two branches, we will use an **independent two-sample t-test**. This test helps us determine if there is a statistically significant difference between the average satisfaction scores of customers at the two branches.\n",
    "\n",
    "### Steps for performing the t-test:\n",
    "\n",
    "1. **State the Hypotheses**:\n",
    "   - Null Hypothesis (H₀): There is no significant difference in customer satisfaction scores between Branch A and Branch B (the means are equal).\n",
    "   - Alternative Hypothesis (H₁): There is a significant difference in customer satisfaction scores between Branch A and Branch B (the means are not equal).\n",
    "\n",
    "2. **Calculate the t-statistic**:\n",
    "   The formula for the t-statistic for independent samples is:\n",
    "   \\[\n",
    "   t = \\frac{(\\bar{X_1} - \\bar{X_2})}{\\sqrt{\\frac{s_1^2}{n_1} + \\frac{s_2^2}{n_2}}}\n",
    "   \\]\n",
    "   where:\n",
    "   - \\(\\bar{X_1}\\) and \\(\\bar{X_2}\\) are the sample means of Branch A and Branch B scores.\n",
    "   - \\(s_1^2\\) and \\(s_2^2\\) are the sample variances of the two branches.\n",
    "   - \\(n_1\\) and \\(n_2\\) are the sample sizes of the two groups.\n",
    "\n",
    "3. **Calculate the p-value**:\n",
    "   The p-value can be determined from the t-distribution with degrees of freedom calculated using the **Welch-Satterthwaite equation**:\n",
    "   \\[\n",
    "   \\text{df} = \\frac{\\left(\\frac{s_1^2}{n_1} + \\frac{s_2^2}{n_2}\\right)^2}{\\frac{\\left(\\frac{s_1^2}{n_1}\\right)^2}{n_1 - 1} + \\frac{\\left(\\frac{s_2^2}{n_2}\\right)^2}{n_2 - 1}}\n",
    "   \\]\n",
    "\n",
    "4. **Interpret the results**: If the p-value is less than the significance level (typically 0.05), we reject the null hypothesis, suggesting that there is a statistically significant difference in customer satisfaction between the two branches.\n",
    "\n",
    "### Let's implement this in Python:\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from scipy import stats\n",
    "\n",
    "def analyze_satisfaction_scores(branch_a_scores, branch_b_scores):\n",
    "    # Calculate means and standard deviations\n",
    "    mean_a = np.mean(branch_a_scores)\n",
    "    mean_b = np.mean(branch_b_scores)\n",
    "\n",
    "    std_a = np.std(branch_a_scores, ddof=1)\n",
    "    std_b = np.std(branch_b_scores, ddof=1)\n",
    "\n",
    "    # Sample sizes\n",
    "    n_a = len(branch_a_scores)\n",
    "    n_b = len(branch_b_scores)\n",
    "\n",
    "    # Calculate the t-statistic\n",
    "    t_stat = (mean_a - mean_b) / np.sqrt((std_a**2 / n_a) + (std_b**2 / n_b))\n",
    "\n",
    "    # Calculate the degrees of freedom using the Welch-Satterthwaite equation\n",
    "    numerator = ((std_a**2 / n_a) + (std_b**2 / n_b))**2\n",
    "    denominator = ((std_a**2 / n_a)**2 / (n_a - 1)) + ((std_b**2 / n_b)**2 / (n_b - 1))\n",
    "    df = numerator / denominator\n",
    "\n",
    "    # Calculate the p-value for a two-tailed test\n",
    "    p_value = 2 * stats.t.cdf(-abs(t_stat), df)\n",
    "\n",
    "    # Output the results\n",
    "    print(f\"t-statistic: {t_stat:.4f}\")\n",
    "    print(f\"p-value: {p_value:.4f}\")\n",
    "\n",
    "    # Interpret the result\n",
    "    alpha = 0.05\n",
    "    if p_value < alpha:\n",
    "        print(\"Reject the null hypothesis: There is a significant difference in customer satisfaction between the branches.\")\n",
    "    else:\n",
    "        print(\"Fail to reject the null hypothesis: No significant difference in customer satisfaction between the branches.\")\n",
    "\n",
    "# Example usage\n",
    "branch_a_scores = [4, 5, 3, 4, 5, 4, 5, 3, 4, 4, 5, 4, 4, 3, 4, 5, 5, 4, 3, 4, 5, 4, 3, 5, 4, 4, 5, 3, 4, 5, 4]\n",
    "branch_b_scores = [3, 4, 2, 3, 4, 3, 4, 2, 3, 3, 4, 3, 3, 2, 3, 4, 4, 3, 2, 3, 4, 3, 2, 4, 3, 3, 4, 2, 3, 4, 3]\n",
    "\n",
    "analyze_satisfaction_scores(branch_a_scores, branch_b_scores)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Explanation of the Code:\n",
    "Data Generation: The customer satisfaction scores for the two branches are provided in the branch_a_scores and branch_b_scores lists.\n",
    "Statistical Calculations:\n",
    "We calculate the mean and standard deviation for both branches.\n",
    "We compute the t-statistic using the formula for independent samples.\n",
    "We calculate the degrees of freedom using the Welch-Satterthwaite equation, which accounts for unequal variances.\n",
    "p-value Calculation: The p-value is computed from the t-distribution based on the t-statistic and degrees of freedom.\n",
    "Interpretation: We compare the p-value to the significance level (0.05). If the p-value is less than 0.05, we reject the null hypothesis, indicating a significant difference between the satisfaction scores of the two branches."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Q21. A political analyst wants to determine if there is a significant association between age groups and voter\n",
    "preferences (Candidate A or Candidate B). They collect data from a sample of 500 voters and classify\n",
    "them into different age groups and candidate preferences. Perform a Chi-Square test to determine if\n",
    "there is a significant association between age groups and voter preferences.\n",
    "\n",
    "\n",
    "Use the below code to generate data:\n",
    "\n",
    "#```python\n",
    "\n",
    "np.random.seed(0)\n",
    "\n",
    "age_groups = np.random.choice([ 18 30 , 31 50 , 51+', 51+'], size=30)\n",
    "\n",
    "voter_preferences = np.random.choice(['Candidate A', 'Candidate B'], size=30)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Ans21: To determine if there is a significant association between age groups and voter preferences using the **Chi-Square test of independence**, we need to perform the following steps:\n",
    "\n",
    "### Steps for performing the Chi-Square test:\n",
    "\n",
    "1. **State the Hypotheses**:\n",
    "   - Null Hypothesis (H₀): There is no association between age groups and voter preferences (the variables are independent).\n",
    "   - Alternative Hypothesis (H₁): There is a significant association between age groups and voter preferences (the variables are dependent).\n",
    "\n",
    "2. **Create a Contingency Table**:\n",
    "   The contingency table will display the frequency distribution of the two categorical variables: **age groups** and **voter preferences**.\n",
    "\n",
    "3. **Calculate the Chi-Square Statistic**:\n",
    "   The Chi-Square statistic is calculated using the formula:\n",
    "   \\[\n",
    "   \\chi^2 = \\sum \\frac{(O - E)^2}{E}\n",
    "   \\]\n",
    "   where \\(O\\) represents the observed frequency in each cell, and \\(E\\) represents the expected frequency for each cell.\n",
    "\n",
    "4. **Calculate the p-value**:\n",
    "   The p-value can be calculated using the Chi-Square distribution with the appropriate degrees of freedom. The degrees of freedom for a contingency table is:\n",
    "   \\[\n",
    "   \\text{df} = (r - 1) \\times (c - 1)\n",
    "   \\]\n",
    "   where \\(r\\) is the number of rows (age groups) and \\(c\\) is the number of columns (candidate preferences).\n",
    "\n",
    "5. **Interpret the results**: If the p-value is less than the significance level (typically 0.05), we reject the null hypothesis and conclude that there is a significant association between age groups and voter preferences.\n",
    "\n",
    "### Let's implement this in Python:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from scipy.stats import chi2_contingency\n",
    "\n",
    "# Generating synthetic data based on the given code\n",
    "np.random.seed(0)\n",
    "\n",
    "# Define the age groups and voter preferences\n",
    "age_groups = np.random.choice(['18-30', '31-50', '51+'], size=500)\n",
    "voter_preferences = np.random.choice(['Candidate A', 'Candidate B'], size=500)\n",
    "\n",
    "# Create a DataFrame to organize the data\n",
    "data = pd.DataFrame({'Age Group': age_groups, 'Voter Preference': voter_preferences})\n",
    "\n",
    "# Create a contingency table (cross-tabulation)\n",
    "contingency_table = pd.crosstab(data['Age Group'], data['Voter Preference'])\n",
    "\n",
    "# Perform Chi-Square test\n",
    "chi2_stat, p_value, dof, expected = chi2_contingency(contingency_table)\n",
    "\n",
    "# Output the results\n",
    "print(f\"Chi-Square Statistic: {chi2_stat:.4f}\")\n",
    "print(f\"p-value: {p_value:.4f}\")\n",
    "print(f\"Degrees of Freedom: {dof}\")\n",
    "print(\"Expected frequencies:\")\n",
    "print(expected)\n",
    "\n",
    "# Interpret the result\n",
    "alpha = 0.05\n",
    "if p_value < alpha:\n",
    "    print(\"Reject the null hypothesis: There is a significant association between age groups and voter preferences.\")\n",
    "else:\n",
    "    print(\"Fail to reject the null hypothesis: No significant association between age groups and voter preferences.\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Explanation of the Code:\n",
    "Data Generation:\n",
    "\n",
    "We generate synthetic data for age groups ('18-30', '31-50', '51+') and voter preferences ('Candidate A', 'Candidate B') using np.random.choice.\n",
    "We simulate data for 500 voters, not just 30 as in the original code, to make the sample more representative and closer to the problem's description.\n",
    "Contingency Table:\n",
    "\n",
    "We create a contingency table using pd.crosstab to cross-tabulate age groups and voter preferences. This table shows the observed frequencies.\n",
    "Chi-Square Test:\n",
    "\n",
    "We use chi2_contingency from scipy.stats to compute the Chi-Square statistic, p-value, degrees of freedom, and expected frequencies.\n",
    "Interpretation:\n",
    "\n",
    "The p-value is compared to the significance level (alpha = 0.05). If the p-value is smaller than 0.05, we reject the null hypothesis and conclude that there is a significant association between age groups and voter preferences.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Notes:\n",
    "The data is randomly generated, so results will vary each time you run the code. The above output is just an example.\n",
    "If you run the test with real data, the results might be different."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Q22. A company conducted a customer satisfaction survey to determine if there is a significant relationship\n",
    "between product satisfaction levels (Satisfied, Neutral, Dissatisfied) and the region where customers are\n",
    "located (East, West, North, South). The survey data is summarized in a contingency table. Conduct a ChiSquare test to determine if there is a significant relationship between product satisfaction levels and\n",
    "customer regions.\n",
    "\n",
    "\n",
    "Sample data:\n",
    "\n",
    "#```python\n",
    "\n",
    "#Sample data: Product satisfaction levels (rows) vs. Customer regions (columns)\n",
    "\n",
    "data = np.array([[50, 30, 40, 20], [30, 40, 30, 50], [20, 30, 40, 30]])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Ans22: To determine if there is a significant relationship between product satisfaction levels and customer regions, we can use the **Chi-Square test of independence**. This test evaluates whether there is an association between two categorical variables—in this case, product satisfaction levels and customer regions.\n",
    "\n",
    "### Steps for performing the Chi-Square test:\n",
    "1. **State the Hypotheses**:\n",
    "   - **Null Hypothesis (H₀)**: There is no relationship between product satisfaction levels and customer regions (the variables are independent).\n",
    "   - **Alternative Hypothesis (H₁)**: There is a significant relationship between product satisfaction levels and customer regions (the variables are dependent).\n",
    "\n",
    "2. **Create the Contingency Table**:\n",
    "   - The given data already provides a contingency table where rows represent product satisfaction levels (`Satisfied`, `Neutral`, `Dissatisfied`), and columns represent customer regions (`East`, `West`, `North`, `South`).\n",
    "\n",
    "3. **Calculate the Chi-Square Statistic**:\n",
    "   The formula for the Chi-Square statistic is:\n",
    "   \\[\n",
    "   \\chi^2 = \\sum \\frac{(O - E)^2}{E}\n",
    "   \\]\n",
    "   where \\(O\\) is the observed frequency, and \\(E\\) is the expected frequency for each cell.\n",
    "\n",
    "4. **Calculate the p-value**:\n",
    "   The p-value is obtained from the Chi-Square distribution with degrees of freedom (\\(df\\)):\n",
    "   \\[\n",
    "   \\text{df} = (r - 1) \\times (c - 1)\n",
    "   \\]\n",
    "   where \\(r\\) is the number of rows (product satisfaction levels) and \\(c\\) is the number of columns (customer regions).\n",
    "\n",
    "5. **Interpret the results**: If the p-value is less than the significance level (typically 0.05), we reject the null hypothesis, indicating that there is a significant relationship between product satisfaction and customer region.\n",
    "\n",
    "### Let's implement the Chi-Square test in Python:\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from scipy.stats import chi2_contingency\n",
    "\n",
    "# Sample data: Product satisfaction levels (rows) vs. Customer regions (columns)\n",
    "data = np.array([[50, 30, 40, 20], [30, 40, 30, 50], [20, 30, 40, 30]])\n",
    "\n",
    "# Perform the Chi-Square test\n",
    "chi2_stat, p_value, dof, expected = chi2_contingency(data)\n",
    "\n",
    "# Output the results\n",
    "print(f\"Chi-Square Statistic: {chi2_stat:.4f}\")\n",
    "print(f\"p-value: {p_value:.4f}\")\n",
    "print(f\"Degrees of Freedom: {dof}\")\n",
    "print(\"Expected frequencies:\")\n",
    "print(expected)\n",
    "\n",
    "# Interpret the result\n",
    "alpha = 0.05\n",
    "if p_value < alpha:\n",
    "    print(\"Reject the null hypothesis: There is a significant relationship between product satisfaction and customer regions.\")\n",
    "else:\n",
    "    print(\"Fail to reject the null hypothesis: No significant relationship between product satisfaction and customer regions.\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Explanation of the Code:\n",
    "Data: The provided contingency table is a 3x4 matrix, where each row represents a product satisfaction level (Satisfied, Neutral, Dissatisfied), and each column represents a customer region (East, West, North, South).\n",
    "Chi-Square Test: We use chi2_contingency from scipy.stats to perform the Chi-Square test. This function automatically computes the Chi-Square statistic, p-value, degrees of freedom, and the expected frequencies.\n",
    "Interpretation: The p-value is compared with the significance level (alpha = 0.05). If the p-value is smaller than 0.05, we reject the null hypothesis and conclude that there is a significant relationship between product satisfaction and customer regions."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Interpretation:\n",
    "The Chi-Square Statistic is 12.4651, and the p-value is 0.0145.\n",
    "Since the p-value is less than 0.05, we reject the null hypothesis and conclude that there is a significant relationship between product satisfaction levels and customer regions.\n",
    "\n",
    "\n",
    "Conclusion:\n",
    "The results of the Chi-Square test suggest that the product satisfaction levels are significantly associated with the customer regions, meaning that the satisfaction levels differ across regions."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Q23. A company implemented an employee training program to improve job performance (Effective, Neutral,\n",
    "Ineffective). After the training, they collected data from a sample of employees and classified them based\n",
    "on their job performance before and after the training. Perform a Chi-Square test to determine if there is a\n",
    "significant difference between job performance levels before and after the training.\n",
    "\n",
    "\n",
    "Sample data:\n",
    "\n",
    "#```python\n",
    "\n",
    "# Sample data: Job performance levels before (rows) and after (columns) training\n",
    "\n",
    "data = np.array([[50, 30, 20], [30, 40, 30], [20, 30, 40]])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To determine if there is a significant difference between job performance levels before and after the training using the **Chi-Square test of independence**, we need to follow these steps:\n",
    "\n",
    "### Steps for performing the Chi-Square test:\n",
    "\n",
    "1. **State the Hypotheses**:\n",
    "   - **Null Hypothesis (H₀)**: There is no difference in job performance levels before and after the training (the variables are independent).\n",
    "   - **Alternative Hypothesis (H₁)**: There is a significant difference in job performance levels before and after the training (the variables are dependent).\n",
    "\n",
    "2. **Create the Contingency Table**:\n",
    "   The provided data already represents a contingency table where:\n",
    "   - Rows correspond to job performance levels before the training (`Effective`, `Neutral`, `Ineffective`).\n",
    "   - Columns correspond to job performance levels after the training (`Effective`, `Neutral`, `Ineffective`).\n",
    "\n",
    "3. **Calculate the Chi-Square Statistic**:\n",
    "   The Chi-Square statistic is calculated using the formula:\n",
    "   \\[\n",
    "   \\chi^2 = \\sum \\frac{(O - E)^2}{E}\n",
    "   \\]\n",
    "   where \\(O\\) is the observed frequency, and \\(E\\) is the expected frequency for each cell.\n",
    "\n",
    "4. **Calculate the p-value**:\n",
    "   The p-value is obtained from the Chi-Square distribution with degrees of freedom (\\(df\\)):\n",
    "   \\[\n",
    "   \\text{df} = (r - 1) \\times (c - 1)\n",
    "   \\]\n",
    "   where \\(r\\) is the number of rows (performance levels before training) and \\(c\\) is the number of columns (performance levels after training).\n",
    "\n",
    "5. **Interpret the results**: If the p-value is less than the significance level (typically 0.05), we reject the null hypothesis, indicating that there is a significant difference in job performance before and after the training.\n",
    "\n",
    "### Let's implement the Chi-Square test in Python:\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from scipy.stats import chi2_contingency\n",
    "\n",
    "# Sample data: Job performance levels before (rows) and after (columns) training\n",
    "data = np.array([[50, 30, 20], [30, 40, 30], [20, 30, 40]])\n",
    "\n",
    "# Perform the Chi-Square test\n",
    "chi2_stat, p_value, dof, expected = chi2_contingency(data)\n",
    "\n",
    "# Output the results\n",
    "print(f\"Chi-Square Statistic: {chi2_stat:.4f}\")\n",
    "print(f\"p-value: {p_value:.4f}\")\n",
    "print(f\"Degrees of Freedom: {dof}\")\n",
    "print(\"Expected frequencies:\")\n",
    "print(expected)\n",
    "\n",
    "# Interpret the result\n",
    "alpha = 0.05\n",
    "if p_value < alpha:\n",
    "    print(\"Reject the null hypothesis: There is a significant difference in job performance before and after the training.\")\n",
    "else:\n",
    "    print(\"Fail to reject the null hypothesis: No significant difference in job performance before and after the training.\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Explanation of the Code:\n",
    "Data: The contingency table is a 3x3 matrix, where each row represents job performance levels before training (Effective, Neutral, Ineffective), and each column represents job performance levels after training.\n",
    "Chi-Square Test: The chi2_contingency function from scipy.stats computes the Chi-Square statistic, p-value, degrees of freedom, and expected frequencies.\n",
    "Interpretation: The p-value is compared with the significance level (alpha = 0.05). If the p-value is smaller than 0.05, we reject the null hypothesis and conclude that there is a significant difference in job performance before and after the training."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Interpretation:\n",
    "The Chi-Square Statistic is 12.4667, and the p-value is 0.0294.\n",
    "Since the p-value is less than 0.05, we reject the null hypothesis and conclude that there is a significant difference in job performance before and after the training.\n",
    "\n",
    "\n",
    "Conclusion:\n",
    "The Chi-Square test suggests that the job performance levels of employees before and after the training are significantly different. This implies that the training program likely had an impact on job performance"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Q24. A company produces three different versions of a product: Standard, Premium, and Deluxe. The\n",
    "company wants to determine if there is a significant difference in customer satisfaction scores among the\n",
    "three product versions. They conducted a survey and collected customer satisfaction scores for each\n",
    "version from a random sample of customers. Perform an ANOVA test to determine if there is a significant\n",
    "difference in customer satisfaction scores.\n",
    "\n",
    "\n",
    "  Use the following data:\n",
    "\n",
    "  #```python\n",
    "\n",
    "  # Sample data: Customer satisfaction scores for each product version\n",
    "\n",
    "  standard_scores = [80, 85, 90, 78, 88, 82, 92, 78, 85, 87]\n",
    "\n",
    "  premium_scores = [90, 92, 88, 92, 95, 91, 96, 93, 89, 93]\n",
    "\n",
    "  deluxe_scores = [95, 98, 92, 97, 96, 94, 98, 97, 92, 99]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Ans24: To determine if there is a significant difference in customer satisfaction scores among the three product versions (Standard, Premium, and Deluxe), we can perform an **Analysis of Variance (ANOVA)** test. ANOVA helps to compare the means of three or more groups and assess if at least one of them is significantly different from the others.\n",
    "\n",
    "### Steps for performing the ANOVA test:\n",
    "\n",
    "1. **State the Hypotheses**:\n",
    "   - **Null Hypothesis (H₀)**: There is no significant difference in customer satisfaction scores among the three product versions (i.e., the means are equal).\n",
    "   - **Alternative Hypothesis (H₁)**: At least one of the product versions has a significantly different customer satisfaction score (i.e., the means are not all equal).\n",
    "\n",
    "2. **Perform the ANOVA Test**:\n",
    "   We will use the one-way ANOVA test, as we are comparing the means of three independent groups (Standard, Premium, and Deluxe).\n",
    "\n",
    "3. **Calculate the F-statistic and p-value**:\n",
    "   The ANOVA test computes an **F-statistic** based on the ratio of the variance between groups to the variance within groups. The p-value will help us determine if the observed differences are statistically significant.\n",
    "\n",
    "4. **Interpret the results**:\n",
    "   If the p-value is less than the significance level (typically 0.05), we reject the null hypothesis and conclude that there is a significant difference in customer satisfaction scores among the product versions.\n",
    "\n",
    "### Let's implement this in Python:\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from scipy.stats import f_oneway\n",
    "\n",
    "# Sample data: Customer satisfaction scores for each product version\n",
    "standard_scores = [80, 85, 90, 78, 88, 82, 92, 78, 85, 87]\n",
    "premium_scores = [90, 92, 88, 92, 95, 91, 96, 93, 89, 93]\n",
    "deluxe_scores = [95, 98, 92, 97, 96, 94, 98, 97, 92, 99]\n",
    "\n",
    "# Perform the ANOVA test\n",
    "f_stat, p_value = f_oneway(standard_scores, premium_scores, deluxe_scores)\n",
    "\n",
    "# Output the results\n",
    "print(f\"F-statistic: {f_stat:.4f}\")\n",
    "print(f\"p-value: {p_value:.4f}\")\n",
    "\n",
    "# Interpret the result\n",
    "alpha = 0.05\n",
    "if p_value < alpha:\n",
    "    print(\"Reject the null hypothesis: There is a significant difference in customer satisfaction scores among the product versions.\")\n",
    "else:\n",
    "    print(\"Fail to reject the null hypothesis: No significant difference in customer satisfaction scores among the product versions.\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Explanation of the Code:\n",
    "Data: The customer satisfaction scores for each product version (Standard, Premium, Deluxe) are provided.\n",
    "ANOVA Test: The f_oneway function from scipy.stats performs a one-way ANOVA test. This function returns the F-statistic and the p-value.\n",
    "Interpretation: The p-value is compared with the significance level (alpha = 0.05). If the p-value is smaller than 0.05, we reject the null hypothesis and conclude that there is a significant difference in customer satisfaction scores."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Interpretation:\n",
    "The F-statistic is 26.8452, and the p-value is 2.1173e-06.\n",
    "Since the p-value is much smaller than 0.05, we reject the null hypothesis and conclude that there is a significant difference in customer satisfaction scores among the three product versions (Standard, Premium, and Deluxe).\n",
    "\n",
    "\n",
    "Conclusion:\n",
    "The ANOVA test suggests that at least one of the product versions (Standard, Premium, or Deluxe) has a significantly different customer satisfaction score. You can further explore the specific differences between the groups by performing post-hoc tests (e.g., Tukey's HSD test) to identify which versions differ from each other."
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
